{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/blob/main/F3_2_AutoTokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## Automatic Tokenization\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F3_2_AutoTokenization.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT5v8LTvdWra"
      },
      "source": [
        "## Wrapping the output in Colab\n",
        "\n",
        "Gabe found the following resource on how to get Google Colab to wrap the output of a cell: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results\n",
        "\n",
        "In short, put the following into a cell and run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eeihWDAFdWrb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvv4B3xTdWrb"
      },
      "source": [
        "## References\n",
        "\n",
        "Python `requests` library quickstart: https://requests.readthedocs.io/en/latest/user/quickstart/\n",
        "\n",
        "Beautiful Soup documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "\n",
        "GPT Tokenizer Illustration: https://platform.openai.com/tokenizer\n",
        "\n",
        "Python `split` method: https://docs.python.org/3/library/stdtypes.html#str.split\n",
        "\n",
        "Hugging Face Byte-Pair Encoding tokenization: https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt\n",
        "\n",
        "Hugging Face WordPiece tokenization: https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GN7qaNLwdWrb",
        "outputId": "176326df-3978-42ca-b14e-a1589be599df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting huggingface_hub<0.17,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.5.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface_hub, transformers\n",
            "Successfully installed huggingface_hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install requests chardet nltk beautifulsoup4 tokenizers transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duAnCx1adWrc",
        "outputId": "539b6d13-f710-45ba-c953-092d02cc7d1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#you shouldn't need to do this in Colab, but I had to do it on my own machine\n",
        "#in order to connect to the nltk service\n",
        "import nltk\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjFzxL0dWrc"
      },
      "source": [
        "## Working with HTML data\n",
        "\n",
        "Most data you retrieve from the web is not in text format - it is usually has lots of html tags like `<title>`, `</br>`, and `<p>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "njfVDLWGdWrc",
        "outputId": "406ecb33-39e4-4721-c4cd-4598c01e6ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "{'date': 'Thu, 28 Sep 2023 16:25:07 GMT', 'vary': 'Accept-Encoding,Cookie', 'server': 'ATS/9.1.4', 'x-content-type-options': 'nosniff', 'content-language': 'en', 'accept-ch': '', 'last-modified': 'Mon, 25 Sep 2023 12:02:48 GMT', 'content-type': 'text/html; charset=UTF-8', 'content-encoding': 'gzip', 'age': '14995', 'x-cache': 'cp1083 hit, cp1077 hit/6', 'x-cache-status': 'hit-front', 'server-timing': 'cache;desc=\"hit-front\", host;desc=\"cp1077\"', 'strict-transport-security': 'max-age=106384710; includeSubDomains; preload', 'report-to': '{ \"group\": \"wm_nel\", \"max_age\": 604800, \"endpoints\": [{ \"url\": \"https://intake-logging.wikimedia.org/v1/events?stream=w3c.reportingapi.network_error&schema_uri=/w3c/reportingapi/network_error/1.0.0\" }] }', 'nel': '{ \"report_to\": \"wm_nel\", \"max_age\": 604800, \"failure_fraction\": 0.05, \"success_fraction\": 0.0}', 'set-cookie': 'WMF-Last-Access=28-Sep-2023;Path=/;HttpOnly;secure;Expires=Mon, 30 Oct 2023 12:00:00 GMT, WMF-Last-Access-Global=28-Sep-2023;Path=/;Domain=.wikipedia.org;HttpOnly;secure;Expires=Mon, 30 Oct 2023 12:00:00 GMT, WMF-DP=a59;Path=/;HttpOnly;secure;Expires=Fri, 29 Sep 2023 00:00:00 GMT, GeoIP=US:SC:North_Charleston:32.86:-79.97:v4; Path=/; secure; Domain=.wikipedia.org, NetworkProbeLimit=0.001;Path=/;Secure;Max-Age=3600', 'x-client-ip': '104.196.202.192', 'cache-control': 'private, s-maxage=0, max-age=0, must-revalidate', 'accept-ranges': 'bytes', 'content-length': '120874'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Sherlock_Holmes\")\n",
        "\n",
        "print(response)\n",
        "print(response.headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mQYWOxICdWrd",
        "outputId": "6061f319-abfc-45f1-946e-43dd775f2713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!DOCTYPE html>\\n<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-zebra-design-disabled vector-feature-custom-font-size-clientpref-disabled vector-feature-client-preferences-disabled\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\">\\n<title>Sherlock Holmes - Wikipedia</title>\\n<script>(function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-zebra-design-disabled vector-feature-custom-font-size-clientpref-disabled vector-feature-client-preferences-disabled\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split(\\'%2C\\').forEach(function(pref){className=className.replace(new RegExp(\\'(^| )\\'+pref.replace(/-clientpref-\\\\w+$|[^\\\\w-]+/g,\\'\\')+\\'-clientpref-\\\\\\\\w+( |$)\\'),\\'$1\\'+pref+\\'$2\\');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\\n\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"425beaa6-5dc4-4b11-945a-09e8c9e7696b\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Sherlock_Holmes\",\"wgTitle\":\"Sherlock Holmes\",\"wgCurRevisionId\":1171425990,\"wgRevisionId\":1171425990,\"wgArticleId\":27159,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"Articles with short description\",\"Short description matches Wikidata\",\"Wikipedia indefinitely semi-protected pages\",\"Use dmy dates from June 2021\",\"Use British English from June 2021\",\"Short description is different from Wikidata\",\"Articles using Infobox character with multiple unlabeled fields\",\"Pages using Sister project links with hidden wikidata\",\"Pages using Sister project links with default search\",\"Articles with FAST identifiers\",\"Articles with ISNI identifiers\",\\n\"Articles with VIAF identifiers\",\"Articles with BIBSYS identifiers\",\"Articles with BNF identifiers\",\"Articles with BNFdata identifiers\",\"Articles with CANTICN identifiers\",\"Articles with GND identifiers\",\"Articles with J9U identifiers\",\"Articles with LCCN identifiers\",\"Articles with Libris identifiers\",\"Articles with NKC identifiers\",\"Articles with NLA identifiers\",\"Articles with NLK identifie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "response.text[:3000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U8QBYeVdWrd"
      },
      "source": [
        "## Beautiful Soup\n",
        "\n",
        "The Beautiful Soup package is great for *parsing* and manipulating HTML: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pPTkB37odWrd",
        "outputId": "aa0e4b46-baa6-4fb3-9d5e-0449d35864f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Sherlock_Holmes\")\n",
        "sherlock_wiki_html = BeautifulSoup(response.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPip8Dv6dWrd"
      },
      "source": [
        "You can look for a title tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WuYJPQuVdWrd",
        "outputId": "e8ff5bd5-6c64-49f5-9fa5-84177836952d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>Sherlock Holmes - Wikipedia</title>\n"
          ]
        }
      ],
      "source": [
        "print(sherlock_wiki_html.title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-l9xqqVdWrd"
      },
      "source": [
        "Or look for all of the `<a>` tags which are the links to other pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w-vek9iSdWrd",
        "outputId": "b2aab7b6-3855-44e7-8145-0cea48ddb60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#bodyContent\n",
            "/wiki/Main_Page\n",
            "/wiki/Wikipedia:Contents\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Special:Random\n",
            "/wiki/Wikipedia:About\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
            "/wiki/Help:Contents\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Special:RecentChanges\n",
            "/wiki/Wikipedia:File_upload_wizard\n",
            "/wiki/Main_Page\n",
            "/wiki/Special:Search\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Sherlock+Holmes\n",
            "/w/index.php?title=Special:UserLogin&returnto=Sherlock+Holmes\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Sherlock+Holmes\n",
            "/w/index.php?title=Special:UserLogin&returnto=Sherlock+Holmes\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Special:MyContributions\n",
            "/wiki/Special:MyTalk\n",
            "#\n",
            "#Inspiration_for_the_character\n",
            "#Fictional_character_biography\n",
            "#Family_and_early_life\n",
            "#Life_with_Watson\n",
            "#Practice\n",
            "#The_Great_Hiatus\n",
            "#Retirement\n",
            "#Personality_and_habits\n",
            "#Drug_use\n",
            "#Finances\n",
            "#Attitudes_towards_women\n",
            "#Irene_Adler\n",
            "#Knowledge_and_skills\n",
            "#Holmesian_deduction\n",
            "#Forensic_science\n",
            "#Disguises\n",
            "#Agents\n",
            "#Combat\n",
            "#Pistols\n",
            "#Other_weapons\n",
            "#Personal_combat\n",
            "#Reception\n",
            "#Popularity\n",
            "#Honours\n",
            "#Societies\n",
            "#Legacy\n",
            "#The_detective_story\n",
            "#\"Elementary,_my_dear_Watson\"\n",
            "#The_Great_Game\n",
            "#Museums_and_special_collections\n",
            "#Postcolonial_criticism\n",
            "#Adaptations_and_derived_works\n",
            "#Related_and_derivative_writings\n",
            "#Adaptations_in_other_media\n",
            "#Copyright_issues\n",
            "#Works\n",
            "#Novels\n",
            "#Short_story_collections\n",
            "#See_also\n",
            "#Notes\n",
            "#Sherlock_Holmes_story_references\n",
            "#Citations\n",
            "#Further_reading\n",
            "#External_links\n",
            "https://ar.wikipedia.org/wiki/%D8%B4%D8%B1%D9%84%D9%88%D9%83_%D9%87%D9%88%D9%84%D9%85%D8%B2\n",
            "https://as.wikipedia.org/wiki/%E0%A6%9B%E0%A6%BE%E0%A7%B0%E0%A7%8D%E0%A6%B2%E0%A6%95_%E0%A6%B9%27%E0%A6%AE%E0%A7%8D%E2%80%8C%E0%A6%9B\n",
            "https://ast.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://az.wikipedia.org/wiki/%C5%9Eerlok_Holms\n",
            "https://bn.wikipedia.org/wiki/%E0%A6%B6%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%B2%E0%A6%95_%E0%A6%B9%E0%A7%8B%E0%A6%AE%E0%A6%B8\n",
            "https://zh-min-nan.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://be.wikipedia.org/wiki/%D0%A8%D1%8D%D1%80%D0%BB%D0%B0%D0%BA_%D0%A5%D0%BE%D0%BB%D0%BC%D1%81\n",
            "https://be-tarask.wikipedia.org/wiki/%D0%A8%D1%8D%D1%80%D0%BB%D0%B0%D0%BA_%D0%93%D0%BE%D0%BB%D0%BC%D0%B7\n",
            "https://bcl.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://bg.wikipedia.org/wiki/%D0%A8%D0%B5%D1%80%D0%BB%D0%BE%D0%BA_%D0%A5%D0%BE%D0%BB%D0%BC%D1%81\n",
            "https://bs.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://br.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://ca.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://cv.wikipedia.org/wiki/%D0%A8%D0%B5%D1%80%D0%BB%D0%BE%D0%BA_%D0%A5%D0%BE%D0%BB%D0%BC%D1%81\n",
            "https://ceb.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://cs.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://cy.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://da.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://de.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://et.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://el.wikipedia.org/wiki/%CE%A3%CE%AD%CF%81%CE%BB%CE%BF%CE%BA_%CE%A7%CE%BF%CE%BB%CE%BC%CF%82\n",
            "https://es.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://eo.wikipedia.org/wiki/%C5%9Cerloko_Holmso\n",
            "https://eu.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://fa.wikipedia.org/wiki/%D8%B4%D8%B1%D9%84%D9%88%DA%A9_%D9%87%D9%88%D9%84%D9%85%D8%B2\n",
            "https://fr.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://fy.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://ga.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://gl.wikipedia.org/wiki/Sherlock_Holmes\n",
            "https://ko.wikipedia.org/wiki/%EC%85%9C%EB%A1%9D_%ED%99%88%EC%A6%88\n",
            "https://hy.wikipedia.org/wiki/%D5%87%D5%A5%D6%80%D5%AC%D5%B8%D6%84_%D5%80%D5%B8%D5%AC%D5%B4%D5%BD\n",
            "https://hi.wikipedia.org/wiki/%E0%A4%B6%E0%A5%87%E0%A4%B0%E0%A4%B2%E0%A5%89%E0%A4%95_%E0%A4%B9%E0%A5%8B%E0%A4%AE%E0%A5%8D%E0%A4%B8\n",
            "https://hsb.wikipedia.org/wiki/Sherlock_Holmes\n"
          ]
        }
      ],
      "source": [
        "list_of_links = sherlock_wiki_html.find_all('a')\n",
        "for link in list_of_links[:100]:\n",
        "    print(link.get('href'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOcxDHjwdWre"
      },
      "source": [
        "## Extracting text with Beautiful Soup\n",
        "\n",
        "Use the `.get_text()` method on the soup object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cu8nSZ2jdWre",
        "outputId": "1720b833-ed5f-412c-ba45-63be4354e742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\nSherlock Holmes - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page across from the title.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate accountLog in\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\n Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1Inspiration for the character\\n\\n\\n\\n\\n\\n\\n\\n2Fictional character biography\\n\\n\\n\\nToggle Fictional character biography subsection\\n\\n\\n\\n\\n\\n2.1Family and early life\\n\\n\\n\\n\\n\\n\\n\\n2.2Life with Watson\\n\\n\\n\\n\\n\\n\\n\\n2.3Practice\\n\\n\\n\\n\\n\\n\\n\\n2.4The Great Hiatus\\n\\n\\n\\n\\n\\n\\n\\n2.5Retirement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3Personality and habits\\n\\n\\n\\nToggle Personality and habits subsection\\n\\n\\n\\n\\n\\n3.1Drug use\\n\\n\\n\\n\\n\\n\\n\\n3.2Finances\\n\\n\\n\\n\\n\\n\\n\\n3.3Attitudes towards women\\n\\n\\n\\n\\n\\n3.3.1Irene Adler\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4Knowledge and skills\\n\\n\\n\\nToggle Knowledge and skills subsection\\n\\n\\n\\n\\n\\n4.1Holmesian deduction\\n\\n\\n\\n\\n\\n\\n\\n4.2Forensic science\\n\\n\\n\\n\\n\\n\\n\\n4.3Disguises\\n\\n\\n\\n\\n\\n\\n\\n4.4Agents\\n\\n\\n\\n\\n\\n\\n\\n4.5Combat\\n\\n\\n\\n\\n\\n4.5.1Pistols\\n\\n\\n\\n\\n\\n\\n\\n4.5.2Other weapons\\n\\n\\n\\n\\n\\n\\n\\n4.5.3Personal combat\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5Reception\\n\\n\\n\\nToggle Reception subsection\\n\\n\\n\\n\\n\\n5.1Popularity\\n\\n\\n\\n\\n\\n\\n\\n5.2Honours\\n\\n\\n\\n\\n\\n\\n\\n5.3Societies\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6Legacy\\n\\n\\n\\nToggle Legacy subsection\\n\\n\\n\\n\\n\\n6.1The detective story\\n\\n\\n\\n\\n\\n\\n\\n6.2\"Elementary, my dear Watson\"\\n\\n\\n\\n\\n\\n\\n\\n6.3The Great Game\\n\\n\\n\\n\\n\\n\\n\\n6.4Museums and special collections\\n\\n\\n\\n\\n\\n\\n\\n6.5Postcolonial criticism\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7Adaptations and derived works\\n\\n\\n\\nToggle Adaptations and derived works subsection\\n\\n\\n\\n\\n\\n7.1Related and derivative writings\\n\\n\\n\\n\\n\\n\\n\\n7.2Adaptations in other media\\n\\n\\n\\n\\n\\n\\n\\n7.3Copyright issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8Works\\n\\n\\n\\nToggle Works subsection\\n\\n\\n\\n\\n\\n8.1Novels\\n\\n\\n\\n\\n\\n\\n\\n8.2Short story collections\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n9See also\\n\\n\\n\\n\\n\\n\\n\\n10Notes\\n\\n\\n\\n\\n\\n\\n\\n11Sherlock Holmes story r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sherlock_wiki_text = sherlock_wiki_html.get_text()\n",
        "\n",
        "sherlock_wiki_text[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ata_v98cdWre",
        "outputId": "d735912f-0883-46df-99ba-416b5fdaba87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    Sherlock Holmes - Wikipedia                                   Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload file      Languages  Language links are at the top of the page across from the title.                    Search            Search         Create accountLog in       Personal tools       Create account Log in      \\t\\tPages for logged out editors learn more    ContributionsTalk                            Contents move to sidebar hide     (Top)      1Inspiration for the character        2Fictional character biography    Toggle Fictional character biography subsection      2.1Family and early life        2.2Life with Watson        2.3Practice        2.4The Great Hiatus        2.5Retirement          3Personality and habits    Toggle Personality and habits subsection      3.1Drug use        3.2Finances        3.3Attitudes towards women      3.3.1Irene Adler            4Knowledge and skills    Toggle Knowledge and skills subsection      4.1Holmesian deduction        4.2Forensic science        4.3Disguises        4.4Agents        4.5Combat      4.5.1Pistols        4.5.2Other weapons        4.5.3Personal combat            5Reception    Toggle Reception subsection      5.1Popularity        5.2Honours        5.3Societies          6Legacy    Toggle Legacy subsection      6.1The detective story        6.2\"Elementary, my dear Watson\"        6.3The Great Game        6.4Museums and special collections        6.5Postcolonial criticism          7Adaptations and derived works    Toggle Adaptations and derived works subsection      7.1Related and derivative writings        7.2Adaptations in other media        7.3Copyright issues          8Works    Toggle Works subsection      8.1Novels        8.2Short story collections          9See also        10Notes        11Sherlock Holmes story r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sherlock_wiki_no_lines = sherlock_wiki_text.replace(\"\\n\",\" \")\n",
        "sherlock_wiki_no_lines[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TWKa7dsPdWre",
        "outputId": "f930d121-b24a-4a7f-94e8-3a669ce5134c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    Sherlock Holmes  -  Wikipedia                                   Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload file      Languages  Language links are at the top of the page across from the title .                     Search            Search         Create accountLog in       Personal tools       Create account Log in      \\t\\tPages for logged out editors learn more    ContributionsTalk                            Contents move to sidebar hide      ( Top )       1Inspiration for the character        2Fictional character biography    Toggle Fictional character biography subsection      2 . 1Family and early life        2 . 2Life with Watson        2 . 3Practice        2 . 4The Great Hiatus        2 . 5Retirement          3Personality and habits    Toggle Personality and habits subsection      3 . 1Drug use        3 . 2Finances        3 . 3Attitudes towards women      3 . 3 . 1Irene Adler            4Knowledge and skills    Toggle Knowledge and skills subsection      4 . 1Holmesian deduction        4 . 2Forensic science        4 . 3Disguises        4 . 4Agents        4 . 5Combat      4 . 5 . 1Pistols        4 . 5 . 2Other weapons        4 . 5 . 3Personal combat            5Reception    Toggle Reception subsection      5 . 1Popularity        5 . 2Honours        5 . 3Societies          6Legacy    Toggle Legacy subsection      6 . 1The detective story        6 . 2 \" Elementary ,  my dear Watson \"         6 . 3The Great Game        6 . 4Museums and special collections        6 . 5Postcolonial criticism          7Adaptations and derived works    Toggle Adaptations and derived works subsection      7 . 1Related and derivative writings        7 . 2Adaptations in other media        7 . 3Copyright issues          8Works    Toggle Works subsection      8 . 1Novels        8 . 2Short st'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chars_to_separate = [\",\",\"!\",\"?\",\";\",\":\",\"\\\"\",\"\\'\",\"-\",\".\",\"(\",\")\"]\n",
        "\n",
        "for c in chars_to_separate:\n",
        "    sherlock_wiki_no_lines = sherlock_wiki_no_lines.replace(c,\" \"+c+\" \")\n",
        "\n",
        "sherlock_wiki_no_lines[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7jvYUIgtdWre",
        "outputId": "a33ef09f-67a0-49b4-8190-b6e512057b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sherlock', 'Holmes', '-', 'Wikipedia', 'Jump', 'to', 'content', 'Main', 'menu', 'Main', 'menu', 'move', 'to', 'sidebar', 'hide', 'Navigation', 'Main', 'pageContentsCurrent', 'eventsRandom', 'articleAbout', 'WikipediaContact', 'usDonate', 'Contribute', 'HelpLearn', 'to', 'editCommunity', 'portalRecent', 'changesUpload', 'file', 'Languages', 'Language', 'links', 'are', 'at', 'the', 'top', 'of', 'the', 'page', 'across', 'from', 'the', 'title', '.', 'Search', 'Search', 'Create', 'accountLog', 'in', 'Personal', 'tools', 'Create', 'account', 'Log', 'in', 'Pages', 'for', 'logged', 'out', 'editors', 'learn', 'more', 'ContributionsTalk', 'Contents', 'move', 'to', 'sidebar', 'hide', '(', 'Top', ')', '1Inspiration', 'for', 'the', 'character', '2Fictional', 'character', 'biography', 'Toggle', 'Fictional', 'character', 'biography', 'subsection', '2', '.', '1Family', 'and', 'early', 'life', '2', '.', '2Life', 'with', 'Watson', '2', '.', '3Practice', '2', '.', '4The', 'Great', 'Hiatus', '2', '.', '5Retirement', '3Personality', 'and', 'habits', 'Toggle', 'Personality', 'and', 'habits', 'subsection', '3', '.', '1Drug', 'use', '3', '.', '2Finances', '3', '.', '3Attitudes', 'towards', 'women', '3', '.', '3', '.', '1Irene', 'Adler', '4Knowledge', 'and', 'skills', 'Toggle', 'Knowledge', 'and', 'skills', 'subsection', '4', '.', '1Holmesian', 'deduction', '4', '.', '2Forensic', 'science', '4', '.', '3Disguises', '4', '.', '4Agents', '4', '.', '5Combat', '4', '.', '5', '.', '1Pistols', '4', '.', '5', '.', '2Other', 'weapons', '4', '.', '5', '.', '3Personal', 'combat', '5Reception', 'Toggle', 'Reception', 'subsection', '5', '.', '1Popularity', '5', '.', '2Honours', '5', '.', '3Societies', '6Legacy', 'Toggle', 'Legacy', 'subsection', '6', '.', '1The', 'detective', 'story', '6', '.', '2', '\"', 'Elementary', ',', 'my', 'dear', 'Watson', '\"', '6', '.', '3The', 'Great', 'Game', '6', '.', '4Museums', 'and', 'special', 'collections', '6', '.', '5Postcolonial', 'criticism', '7Adaptations', 'and', 'derived', 'works', 'Toggle', 'Adaptations', 'and', 'derived', 'works', 'subsection', '7', '.', '1Related', 'and', 'derivative', 'writings', '7', '.', '2Adaptations', 'in', 'other', 'media', '7', '.', '3Copyright', 'issues', '8Works', 'Toggle', 'Works', 'subsection', '8', '.', '1Novels', '8', '.', '2Short', 'story', 'collections', '9See', 'also', '10Notes', '11Sherlock', 'Holmes', 'story', 'references', '12Citations', '13Further', 'reading', '14External', 'links', 'Toggle', 'the', 'table', 'of', 'contents', 'Toggle', 'the', 'table', 'of', 'contents', 'Sherlock', 'Holmes', '99', 'languages', 'العربيةঅসমীয়াAsturianuAzərbaycancaবাংলাBân', '-', 'lâm', '-', 'gúБеларускаяБеларуская', '(', 'тарашкевіца', ')', 'Bikol', 'CentralБългарскиBosanskiBrezhonegCatalàЧӑвашлаCebuanoČeštinaCymraegDanskDeutschEestiΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisFryskGaeilgeGalego한국어Հայերենहिन्दीHornjoserbsceHrvatskiBahasa', 'IndonesiaInterlinguaÍslenskaItalianoעבריתಕನ್ನಡქართულიҚазақшаKurdîКыргызчаLatinaLatviešuLëtzebuergeschLietuviųMagyarМакедонскиMalagasyമലയാളംMaltiमराठीمصرىBahasa', 'MelayuМонголမြန်မာဘာသာNāhuatlNederlands日本語Norsk', 'bokmålNorsk', 'nynorskOccitanOʻzbekcha', '/', 'ўзбекчаਪੰਜਾਬੀپنجابیپښتوPolskiPortuguêsRomânăRumantschРусскийScotsShqipSicilianuසිංහලSimple', 'EnglishSlovenčinaSlovenščinaکوردیСрпски', '/', 'srpskiSrpskohrvatski', '/', 'српскохрватскиSuomiSvenskaTagalogதமிழ்Татарча', '/', 'tatarçaไทยТоҷикӣTürkçeУкраїнськаاردوTiếng', 'ViệtWinaray吴语粵語Žemaitėška中文', 'Edit', 'links', 'ArticleTalk', 'English', 'ReadView', 'sourceView', 'history', 'Tools', 'Tools', 'move', 'to', 'sidebar', 'hide', 'Actions', 'ReadView', 'sourceView', 'history', 'General', 'What', 'links', 'hereRelated', 'changesUpload', 'fileSpecial', 'pagesPermanent', 'linkPage', 'informationGet', 'shortened', 'URLCite', 'this', 'pageWikidata', 'item', 'Print/export', 'Download', 'as', 'PDFPrintable', 'version', 'In', 'other', 'projects', 'Wikimedia', 'CommonsWikiquote', 'From', 'Wikipedia', ',', 'the', 'free', 'encyclopedia', 'Fictional', 'character', '(', 'consulting', 'detective', ')', 'created', 'by', 'Sir', 'Arthur', 'Conan', 'Doyle', 'For', 'other', 'uses', ',', 'see', 'Sherlock', 'Holmes', '(', 'disambiguation', ')', '.', 'Fictional', 'character', 'Sherlock', 'HolmesSherlock', 'Holmes', 'characterSherlock', 'Holmes', 'in', 'a', '1904', 'illustration', 'by', 'Sidney', 'PagetFirst', 'appearanceA', 'Study', 'in', 'Scarlet', '(', '1887', ')', 'Last', 'appearance', '\"', 'The', 'Adventure', 'of', 'Shoscombe', 'Old', 'Place', '\"', '(', '1927', ',', 'canon', ')', 'Created', 'bySir', 'Arthur', 'Conan', 'DoyleIn', '-', 'universe', 'informationOccupationConsulting', 'private', 'detectiveFamilyMycroft', 'Holmes', '(', 'brother', ')', 'NationalityBritishBorn1854', 'Sherlock', 'Holmes', '(', '/ˈʃɜːrlɒk', 'ˈhoʊmz/', ')', 'is', 'a', 'fictional', 'detective', 'created', 'by', 'British', 'author', 'Arthur', 'Conan', 'Doyle', '.', 'Referring', 'to', 'himself', 'as', 'a', '\"', 'consulting', 'detective', '\"', 'in', 'the', 'stories', ',', 'Holmes', 'is', 'known', 'for', 'his', 'proficiency', 'with', 'observation', ',', 'deduction', ',', 'forensic', 'science', 'and', 'logical', 'reasoning', 'that', 'borders', 'on', 'the', 'fantastic', ',', 'which', 'he', 'employs', 'when', 'investigating', 'cases', 'for', 'a', 'wide', 'variety', 'of', 'clients', ',', 'including', 'Scotland', 'Yard', '.', 'First']\n"
          ]
        }
      ],
      "source": [
        "sherlock_wiki_tokens = sherlock_wiki_no_lines.split()\n",
        "print(sherlock_wiki_tokens[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXe-lLZHdWre"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Suppose you needed to tokenize lots of Wikipedia pages like this. Can you come up with a strategy for jumping straight to the content like we did with the Project Gutenberg book?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cEKqTtdWre"
      },
      "source": [
        "## NLTK Tokenizers\n",
        "\n",
        "NLTK has some tokenizers - the `punkt` tokenizer is the most popular.\n",
        "\n",
        "It can tokenize by words:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD1v7XO8dWre",
        "outputId": "012dee09-2211-42e8-f8d3-8ddd66506dfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ï', '»', '¿The', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', ',', 'by', 'Arthur', 'Conan', 'Doyle', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'Author', ':', 'Arthur', 'Conan', 'Doyle', 'Release', 'Date', ':', 'November', '29', ',', '2002', '[', 'eBook', '#', '1661', ']', '[', 'Most', 'recently', 'updated', ':', 'May', '20', ',', '2019', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'an', 'anonymous', 'Project', 'Gutenberg', 'volunteer', 'and', 'Jose', 'Menendez', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'ADVENTURES', 'OF', 'SHERLOCK', 'HOLMES', '*', '*', '*', 'cover', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Arthur', 'Conan', 'Doyle', 'Contents', 'I', '.', 'A', 'Scandal', 'in', 'Bohemia', 'II', '.', 'The', 'Red-Headed', 'League', 'III', '.', 'A', 'Case', 'of', 'Identity', 'IV', '.', 'The', 'Boscombe', 'Valley', 'Mystery', 'V.', 'The', 'Five', 'Orange', 'Pips', 'VI', '.', 'The', 'Man', 'with', 'the', 'Twisted', 'Lip', 'VII', '.', 'The', 'Adventure', 'of', 'the', 'Blue', 'Carbuncle', 'VIII', '.', 'The', 'Adventure', 'of', 'the', 'Speckled', 'Band', 'IX', '.', 'The', 'Adventure', 'of', 'the', 'Engineerâ\\x80\\x99s', 'Thumb', 'X', '.', 'The', 'Adventure', 'of', 'the', 'Noble', 'Bachelor', 'XI', '.', 'The', 'Adventure', 'of', 'the', 'Beryl', 'Coronet', 'XII', '.', 'The', 'Adventure', 'of', 'the', 'Copper', 'Beeches', 'I', '.', 'A', 'SCANDAL', 'IN', 'BOHEMIA', 'I', '.', 'To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_the_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.', 'In', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex', '.', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'and', 'that', 'one', 'particularly', ',', 'were', 'abhorrent', 'to', 'his', 'cold', ',', 'precise', 'but', 'admirably', 'balanced', 'mind', '.', 'He', 'was', ',', 'I', 'take', 'it', ',', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen', ',', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position', '.', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passions', ',', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer', '.', 'They', 'were', 'admirable', 'things', 'for', 'the', 'observerâ\\x80\\x94excellent', 'for', 'drawing', 'the', 'veil', 'from', 'menâ\\x80\\x99s', 'motives', 'and', 'actions', '.', 'But', 'for', 'the', 'trained', 'reasoner', 'to', 'admit', 'such', 'intrusions', 'into', 'his', 'own', 'delicate', 'and', 'finely', 'adjusted', 'temperament', 'was', 'to', 'introduce', 'a', 'distracting', 'factor', 'which', 'might', 'throw', 'a', 'doubt', 'upon', 'all', 'his', 'mental', 'results', '.', 'Grit', 'in', 'a', 'sensitive', 'instrument', ',', 'or', 'a', 'crack', 'in', 'one', 'of', 'his', 'own', 'high-power', 'lenses', ',', 'would', 'not', 'be', 'more', 'disturbing', 'than', 'a', 'strong', 'emotion', 'in', 'a', 'nature', 'such', 'as', 'his', '.', 'And', 'yet', 'there', 'was', 'but', 'one', 'woman', 'to', 'him', ',', 'and', 'that', 'woman', 'was', 'the', 'late', 'Irene', 'Adler', ',', 'of', 'dubious', 'and', 'questionable', 'memory', '.', 'I', 'had', 'seen', 'little', 'of', 'Holmes', 'lately', '.', 'My', 'marriage', 'had', 'drifted', 'us', 'away', 'from', 'each', 'other', '.', 'My', 'own', 'complete', 'happiness', ',', 'and', 'the', 'home-centred', 'interests', 'which', 'rise', 'up', 'around', 'the', 'man', 'who', 'first', 'finds', 'himself', 'master', 'of', 'his', 'own', 'establishment', ',', 'were', 'sufficient', 'to', 'absorb', 'all', 'my', 'attention', ',', 'while', 'Holmes', ',', 'who', 'loathed', 'every', 'form', 'of', 'society', 'with', 'his', 'whole', 'Bohemian', 'soul', ',', 'remained', 'in', 'our', 'lodgings', 'in', 'Baker', 'Street', ',', 'buried', 'among', 'his', 'old', 'books', ',', 'and', 'alternating', 'from', 'week', 'to', 'week', 'between', 'cocaine', 'and', 'ambition', ',', 'the', 'drowsiness', 'of', 'the', 'drug', ',', 'and', 'the', 'fierce', 'energy', 'of', 'his', 'own', 'keen', 'nature', '.', 'He', 'was', 'still', ',', 'as', 'ever', ',', 'deeply', 'attracted', 'by', 'the', 'study', 'of', 'crime', ',', 'and', 'occupied', 'his', 'immense', 'faculties', 'and', 'extraordinary', 'powers', 'of', 'observation', 'in', 'following', 'out', 'those', 'clues', ',', 'and', 'clearing', 'up', 'those', 'mysteries', 'which', 'had', 'been', 'abandoned', 'as', 'hopeless', 'by', 'the', 'official', 'police', '.', 'From', 'time', 'to', 'time', 'I', 'heard', 'some', 'vague', 'account', 'of', 'his', 'doings', ':', 'of', 'his', 'summons', 'to', 'Odessa', 'in', 'the', 'case', 'of', 'the', 'Trepoff', 'murder', ',', 'of', 'his', 'clearing', 'up', 'of', 'the', 'singular', 'tragedy', 'of', 'the', 'Atkinson', 'brothers', 'at', 'Trincomalee', ',', 'and', 'finally', 'of', 'the', 'mission', 'which', 'he', 'had', 'accomplished', 'so', 'delicately', 'and', 'successfully', 'for', 'the', 'reigning', 'family', 'of', 'Holland', '.', 'Beyond', 'these', 'signs', 'of', 'his', 'activity', ',', 'however', ',', 'which', 'I', 'merely', 'shared', 'with', 'all', 'the', 'readers', 'of', 'the', 'daily', 'press', ',', 'I', 'knew', 'little', 'of', 'my', 'former', 'friend', 'and', 'companion', '.', 'One', 'nightâ\\x80\\x94it', 'was', 'on', 'the', 'twentieth', 'of', 'March', ',', '1888â\\x80\\x94I', 'was', 'returning', 'from', 'a', 'journey', 'to', 'a', 'patient', '(', 'for', 'I', 'had', 'now', 'returned', 'to', 'civil', 'practice', ')', ',', 'when', 'my', 'way', 'led', 'me', 'through', 'Baker', 'Street', '.', 'As', 'I', 'passed', 'the', 'well-remembered', 'door', ',', 'which', 'must', 'always', 'be', 'associated', 'in', 'my', 'mind', 'with', 'my', 'wooing', ',', 'and', 'with', 'the', 'dark', 'incidents', 'of', 'the', 'Study', 'in', 'Scarlet', ',', 'I', 'was', 'seized', 'with', 'a', 'keen', 'desire', 'to', 'see', 'Holmes', 'again', ',', 'and', 'to', 'know', 'how', 'he', 'was', 'employing', 'his', 'extraordinary', 'powers', '.', 'His', 'rooms', 'were', 'brilliantly', 'lit', ',', 'and', ',', 'even', 'as', 'I', 'looked', 'up', ',', 'I', 'saw', 'his', 'tall', ',', 'spare', 'figure', 'pass', 'twice', 'in', 'a', 'dark', 'silhouette', 'against', 'the', 'blind', '.', 'He', 'was', 'pacing', 'the', 'room', 'swiftly', ',', 'eagerly', ',', 'with', 'his', 'head', 'sunk', 'upon', 'his', 'chest', 'and', 'his', 'hands', 'clasped', 'behind', 'him', '.', 'To', 'me', ',', 'who', 'knew', 'his', 'every', 'mood', 'and', 'habit', ',', 'his', 'attitude', 'and', 'manner', 'told', 'their', 'own', 'story', '.', 'He', 'was', 'at', 'work', 'again', '.', 'He', 'had', 'risen', 'out', 'of', 'his', 'drug-created', 'dreams', 'and', 'was', 'hot', 'upon', 'the', 'scent', 'of', 'some', 'new', 'problem', '.', 'I', 'rang', 'the', 'bell', 'and', 'was', 'shown', 'up', 'to', 'the', 'chamber', 'which', 'had', 'formerly', 'been', 'in', 'part', 'my', 'own', '.', 'His', 'manner', 'was', 'not', 'effusive', '.', 'It', 'seldom', 'was', ';', 'but', 'he', 'was', 'glad', ',', 'I', 'think', ',', 'to', 'see', 'me', '.', 'With', 'hardly', 'a', 'word', 'spoken', ',', 'but', 'with', 'a', 'kindly', 'eye', ',', 'he', 'waved', 'me', 'to']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import requests\n",
        "\n",
        "#nltk.download(\"punkt\") #need to do this the first time you run it\n",
        "\n",
        "response = requests.get(\"https://www.gutenberg.org/files/1661/1661-0.txt\")\n",
        "sherlock_raw_text = response.text\n",
        "\n",
        "sherlock_words = nltk.word_tokenize(sherlock_raw_text)\n",
        "print(sherlock_words[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgsV4bKKdWre"
      },
      "source": [
        "or sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8J8uIokdWre",
        "outputId": "b8ebfca5-8670-4835-8271-f5e30b168a8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ï»¿The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle\\r\\n\\r\\nThis eBook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever.', 'You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this eBook or online at\\r\\nwww.gutenberg.org.', 'If you are not located in the United States, you\\r\\nwill have to check the laws of the country where you are located before\\r\\nusing this eBook.', 'Title: The Adventures of Sherlock Holmes\\r\\n\\r\\nAuthor: Arthur Conan Doyle\\r\\n\\r\\nRelease Date: November 29, 2002 [eBook #1661]\\r\\n[Most recently updated: May 20, 2019]\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCharacter set encoding: UTF-8\\r\\n\\r\\nProduced by: an anonymous Project Gutenberg volunteer and Jose Menendez\\r\\n\\r\\n*** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\\r\\n\\r\\ncover\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe Adventures of Sherlock Holmes\\r\\n\\r\\nby Arthur Conan Doyle\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\n   I.', 'A Scandal in Bohemia\\r\\n   II.', 'The Red-Headed League\\r\\n   III.', 'A Case of Identity\\r\\n   IV.', 'The Boscombe Valley Mystery\\r\\n   V.     The Five Orange Pips\\r\\n   VI.', 'The Man with the Twisted Lip\\r\\n   VII.', 'The Adventure of the Blue Carbuncle\\r\\n   VIII.', 'The Adventure of the Speckled Band\\r\\n   IX.', 'The Adventure of the Engineerâ\\x80\\x99s Thumb\\r\\n   X.', 'The Adventure of the Noble Bachelor\\r\\n   XI.', 'The Adventure of the Beryl Coronet\\r\\n   XII.', 'The Adventure of the Copper Beeches\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nI.', 'A SCANDAL IN BOHEMIA\\r\\n\\r\\n\\r\\nI.', 'To Sherlock Holmes she is always _the_ woman.', 'I have seldom heard him\\r\\nmention her under any other name.', 'In his eyes she eclipses and\\r\\npredominates the whole of her sex.', 'It was not that he felt any emotion\\r\\nakin to love for Irene Adler.', 'All emotions, and that one particularly,\\r\\nwere abhorrent to his cold, precise but admirably balanced mind.', 'He\\r\\nwas, I take it, the most perfect reasoning and observing machine that\\r\\nthe world has seen, but as a lover he would have placed himself in a\\r\\nfalse position.', 'He never spoke of the softer passions, save with a gibe\\r\\nand a sneer.', 'They were admirable things for the observerâ\\x80\\x94excellent for\\r\\ndrawing the veil from menâ\\x80\\x99s motives and actions.', 'But for the trained\\r\\nreasoner to admit such intrusions into his own delicate and finely\\r\\nadjusted temperament was to introduce a distracting factor which might\\r\\nthrow a doubt upon all his mental results.', 'Grit in a sensitive\\r\\ninstrument, or a crack in one of his own high-power lenses, would not\\r\\nbe more disturbing than a strong emotion in a nature such as his.', 'And\\r\\nyet there was but one woman to him, and that woman was the late Irene\\r\\nAdler, of dubious and questionable memory.', 'I had seen little of Holmes lately.', 'My marriage had drifted us away\\r\\nfrom each other.', 'My own complete happiness, and the home-centred\\r\\ninterests which rise up around the man who first finds himself master\\r\\nof his own establishment, were sufficient to absorb all my attention,\\r\\nwhile Holmes, who loathed every form of society with his whole Bohemian\\r\\nsoul, remained in our lodgings in Baker Street, buried among his old\\r\\nbooks, and alternating from week to week between cocaine and ambition,\\r\\nthe drowsiness of the drug, and the fierce energy of his own keen\\r\\nnature.', 'He was still, as ever, deeply attracted by the study of crime,\\r\\nand occupied his immense faculties and extraordinary powers of\\r\\nobservation in following out those clues, and clearing up those\\r\\nmysteries which had been abandoned as hopeless by the official police.', 'From time to time I heard some vague account of his doings: of his\\r\\nsummons to Odessa in the case of the Trepoff murder, of his clearing up\\r\\nof the singular tragedy of the Atkinson brothers at Trincomalee, and\\r\\nfinally of the mission which he had accomplished so delicately and\\r\\nsuccessfully for the reigning family of Holland.', 'Beyond these signs of\\r\\nhis activity, however, which I merely shared with all the readers of\\r\\nthe daily press, I knew little of my former friend and companion.', 'One nightâ\\x80\\x94it was on the twentieth of March, 1888â\\x80\\x94I was returning from a\\r\\njourney to a patient (for I had now returned to civil practice), when\\r\\nmy way led me through Baker Street.', 'As I passed the well-remembered\\r\\ndoor, which must always be associated in my mind with my wooing, and\\r\\nwith the dark incidents of the Study in Scarlet, I was seized with a\\r\\nkeen desire to see Holmes again, and to know how he was employing his\\r\\nextraordinary powers.', 'His rooms were brilliantly lit, and, even as I\\r\\nlooked up, I saw his tall, spare figure pass twice in a dark silhouette\\r\\nagainst the blind.', 'He was pacing the room swiftly, eagerly, with his\\r\\nhead sunk upon his chest and his hands clasped behind him.', 'To me, who\\r\\nknew his every mood and habit, his attitude and manner told their own\\r\\nstory.', 'He was at work again.', 'He had risen out of his drug-created\\r\\ndreams and was hot upon the scent of some new problem.', 'I rang the bell\\r\\nand was shown up to the chamber which had formerly been in part my own.', 'His manner was not effusive.', 'It seldom was; but he was glad, I think,\\r\\nto see me.', 'With hardly a word spoken, but with a kindly eye, he waved\\r\\nme to an armchair, threw across his case of cigars, and indicated a\\r\\nspirit case and a gasogene in the corner.', 'Then he stood before the fire\\r\\nand looked me over in his singular introspective fashion.', 'â\\x80\\x9cWedlock suits you,â\\x80\\x9d he remarked.', 'â\\x80\\x9cI think, Watson, that you have put\\r\\non seven and a half pounds since I saw you.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cSeven!â\\x80\\x9d I answered.', 'â\\x80\\x9cIndeed, I should have thought a little more.', 'Just a trifle more, I\\r\\nfancy, Watson.', 'And in practice again, I observe.', 'You did not tell me\\r\\nthat you intended to go into harness.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cThen, how do you know?â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cI see it, I deduce it.', 'How do I know that you have been getting\\r\\nyourself very wet lately, and that you have a most clumsy and careless\\r\\nservant girl?â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cMy dear Holmes,â\\x80\\x9d said I, â\\x80\\x9cthis is too much.', 'You would certainly have\\r\\nbeen burned, had you lived a few centuries ago.', 'It is true that I had a\\r\\ncountry walk on Thursday and came home in a dreadful mess, but as I\\r\\nhave changed my clothes I canâ\\x80\\x99t imagine how you deduce it.', 'As to Mary\\r\\nJane, she is incorrigible, and my wife has given her notice, but there,\\r\\nagain, I fail to see how you work it out.â\\x80\\x9d\\r\\n\\r\\nHe chuckled to himself and rubbed his long, nervous hands together.', 'â\\x80\\x9cIt is simplicity itself,â\\x80\\x9d said he; â\\x80\\x9cmy eyes tell me that on the inside\\r\\nof your left shoe, just where the firelight strikes it, the leather is\\r\\nscored by six almost parallel cuts.', 'Obviously they have been caused by\\r\\nsomeone who has very carelessly scraped round the edges of the sole in\\r\\norder to remove crusted mud from it.', 'Hence, you see, my double\\r\\ndeduction that you had been out in vile weather, and that you had a\\r\\nparticularly malignant boot-slitting specimen of the London slavey.', 'As\\r\\nto your practice, if a gentleman walks into my rooms smelling of\\r\\niodoform, with a black mark of nitrate of silver upon his right\\r\\nforefinger, and a bulge on the right side of his top-hat to show where\\r\\nhe has secreted his stethoscope, I must be dull, indeed, if I do not\\r\\npronounce him to be an active member of the medical profession.â\\x80\\x9d\\r\\n\\r\\nI could not help laughing at the ease with which he explained his\\r\\nprocess of deduction.', 'â\\x80\\x9cWhen I hear you give your reasons,â\\x80\\x9d I remarked,\\r\\nâ\\x80\\x9cthe thing always appears to me to be so ridiculously simple that I\\r\\ncould easily do it myself, though at each successive instance of your\\r\\nreasoning I am baffled until you explain your process.', 'And yet I\\r\\nbelieve that my eyes are as good as yours.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cQuite so,â\\x80\\x9d he answered, lighting a cigarette, and throwing himself\\r\\ndown into an armchair.', 'â\\x80\\x9cYou see, but you do not observe.', 'The\\r\\ndistinction is clear.', 'For example, you have frequently seen the steps\\r\\nwhich lead up from the hall to this room.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cFrequently.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cHow often?â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cWell, some hundreds of times.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cThen how many are there?â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cHow many?', 'I donâ\\x80\\x99t know.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cQuite so!', 'You have not observed.', 'And yet you have seen.', 'That is just\\r\\nmy point.', 'Now, I know that there are seventeen steps, because I have\\r\\nboth seen and observed.', 'By the way, since you are interested in these\\r\\nlittle problems, and since you are good enough to chronicle one or two\\r\\nof my trifling experiences, you may be interested in this.â\\x80\\x9d He threw\\r\\nover a sheet of thick, pink-tinted notepaper which had been lying open\\r\\nupon the table.', 'â\\x80\\x9cIt came by the last post,â\\x80\\x9d said he.', 'â\\x80\\x9cRead it aloud.â\\x80\\x9d\\r\\n\\r\\nThe note was undated, and without either signature or address.', 'â\\x80\\x9cThere will call upon you to-night, at a quarter to eight oâ\\x80\\x99clock,â\\x80\\x9d it\\r\\nsaid, â\\x80\\x9ca gentleman who desires to consult you upon a matter of the very\\r\\ndeepest moment.', 'Your recent services to one of the royal houses of\\r\\nEurope have shown that you are one who may safely be trusted with\\r\\nmatters which are of an importance which can hardly be exaggerated.', 'This account of you we have from all quarters received.', 'Be in your\\r\\nchamber then at that hour, and do not take it amiss if your visitor\\r\\nwear a mask.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cThis is indeed a mystery,â\\x80\\x9d I remarked.', 'â\\x80\\x9cWhat do you imagine that it\\r\\nmeans?â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cI have no data yet.', 'It is a capital mistake to theorise before one has\\r\\ndata.', 'Insensibly one begins to twist facts to suit theories, instead of\\r\\ntheories to suit facts.', 'But the note itself.', 'What do you deduce from\\r\\nit?â\\x80\\x9d\\r\\n\\r\\nI carefully examined the writing, and the paper upon which it was\\r\\nwritten.', 'â\\x80\\x9cThe man who wrote it was presumably well to do,â\\x80\\x9d I remarked,\\r\\nendeavouring to imitate my companionâ\\x80\\x99s processes.', 'â\\x80\\x9cSuch paper could not\\r\\nbe bought under half a crown a packet.', 'It is peculiarly strong and\\r\\nstiff.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cPeculiarâ\\x80\\x94that is the very word,â\\x80\\x9d said Holmes.', 'â\\x80\\x9cIt is not an English\\r\\npaper at all.', 'Hold it up to the light.â\\x80\\x9d\\r\\n\\r\\nI did so, and saw a large â\\x80\\x9cEâ\\x80\\x9d with a small â\\x80\\x9cg,â\\x80\\x9d a â\\x80\\x9cP,â\\x80\\x9d and a large â\\x80\\x9cGâ\\x80\\x9d\\r\\nwith a small â\\x80\\x9ctâ\\x80\\x9d woven into the texture of the paper.', 'â\\x80\\x9cWhat do you make of that?â\\x80\\x9d asked Holmes.', 'â\\x80\\x9cThe name of the maker, no doubt; or his monogram, rather.â\\x80\\x9d\\r\\n\\r\\nâ\\x80\\x9cNot at all.', 'The â\\x80\\x98Gâ\\x80\\x99 with the small â\\x80\\x98tâ\\x80\\x99 stands for â\\x80\\x98Gesellschaft,â\\x80\\x99\\r\\nwhich is the German for â\\x80\\x98Company.â\\x80\\x99 It is a customary contraction like\\r\\nour â\\x80\\x98Co.â\\x80\\x99 â\\x80\\x98P,â\\x80\\x99 of course, stands for â\\x80\\x98Papier.â\\x80\\x99 Now for the â\\x80\\x98Eg.â\\x80\\x99 Let us\\r\\nglance at our Continental Gazetteer.â\\x80\\x9d He took down a heavy brown volume\\r\\nfrom his shelves.', 'â\\x80\\x9cEglow, Eglonitzâ\\x80\\x94here we are, Egria.', 'It is in a\\r\\nGerman-speaking countryâ\\x80\\x94in Bohemia, not far from Carlsbad.', 'â\\x80\\x98Remarkable\\r\\nas being the scene of the death of Wallenstein, and for its numerous\\r\\nglass-factories and paper-mills.â\\x80\\x99 Ha, ha, my boy, what do you make of\\r\\nthat?â\\x80\\x9d His eyes sparkled, and he sent up a great blue triumphant cloud\\r\\nfrom his cigarette.', 'â\\x80\\x9cThe paper was made in Bohemia,â\\x80\\x9d I said.', 'â\\x80\\x9cPrecisely.', 'And the man who wrote the note is a German.', 'Do you note the\\r\\npeculiar construction of the sentenceâ\\x80\\x94â\\x80\\x98This account of you we have from\\r\\nall quarters received.â\\x80\\x99 A Frenchman or Russian could not have written\\r\\nthat.', 'It is the German who is so uncourteous to his verbs.', 'It only\\r\\nremains, therefore, to discover what is wanted by this German who\\r\\nwrites upon Bohemian paper and prefers wearing a mask to showing his\\r\\nface.', 'And here he comes, if I am not mistaken, to resolve all our\\r\\ndoubts.â\\x80\\x9d\\r\\n\\r\\nAs he spoke there was the sharp sound of horsesâ\\x80\\x99 hoofs and grating\\r\\nwheels against the curb, followed by a sharp pull at the bell.', 'Holmes\\r\\nwhistled.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import requests\n",
        "\n",
        "#nltk.download(\"punkt\") #only need to do this once\n",
        "\n",
        "response = requests.get(\"https://www.gutenberg.org/files/1661/1661-0.txt\")\n",
        "sherlock_raw_text = response.text\n",
        "\n",
        "sherlock_sentences = nltk.sent_tokenize(sherlock_raw_text)\n",
        "print(sherlock_sentences[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAZd15RFdWre"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "It seems that there are still some strange characters - can you preprocess the text to fix them before using the NLTK tokenizer?\n",
        "\n",
        "Could you structure the words by sentences like we did earlier?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfO7pp54dWre"
      },
      "source": [
        "## Automatic Tokenizers\n",
        "\n",
        "Rather than having to program specific rules for how to tokenize your text, you could learn to do it automatically.\n",
        "\n",
        "Two popular algorithms:\n",
        "* Byte-Pair Encoding tokenization (used by OpenAI's GPT)\n",
        "* WordPiece tokenization (used by Google's BERT)\n",
        "\n",
        "Main idea:\n",
        "* do some normalization and pre-tokenization - like the rule-based tokenization we used to form characters into sequences separated by spaces\n",
        "* start with a vocabulary where each character is a different possible token\n",
        "* find the most frequent consecutive pair, merge them together into a new token\n",
        "* keep going until your vocabulary is a desired size\n",
        "\n",
        "Frequent words - don't break them apart\n",
        "\n",
        "Less-frequent words - represent them as several subwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4F2-yZadWrf"
      },
      "source": [
        "For WordPiece, `##` represents a partial word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYG5NSx2dWrf",
        "outputId": "09e0b569-f843-4a84-c270-cc672f0f48ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (143279 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ï', '»', '¿', 'The', 'Project', 'G', '##ute', '##nberg', 'e', '##B', '##ook', 'of', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', ',', 'by', 'Arthur', 'Conan', 'Doyle', 'This', 'e', '##B', '##ook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're', '-', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'G', '##ute', '##nberg', 'License', 'included', 'with', 'this', 'e', '##B', '##ook', 'or', 'online', 'at', 'www', '.', 'gut', '##enberg', '.', 'org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'e', '##B', '##ook', '.', 'Title', ':', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'Author', ':', 'Arthur', 'Conan', 'Doyle', 'Release', 'Date', ':', 'November', '29', ',', '2002', '[', 'e', '##B', '##ook', '#', '1661', ']', '[', 'Most', 'recently', 'updated', ':', 'May', '20', ',', '2019', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'U', '##TF', '-', '8', 'Produced', 'by', ':', 'an', 'anonymous', 'Project', 'G', '##ute', '##nberg', 'volunteer', 'and', 'Jose', 'Men', '##end', '##ez', '*', '*', '*', 'ST', '##AR', '##T', 'OF', 'THE', 'PR', '##O', '##J', '##EC', '##T', 'G', '##UT', '##EN', '##BE', '##R', '##G', 'E', '##BO', '##OK', 'THE', 'AD', '##VE', '##NT', '##UR', '##ES', 'OF', 'SH', '##ER', '##L', '##OC', '##K', 'H', '##OL', '##ME', '##S', '*', '*', '*', 'cover', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Arthur', 'Conan', 'Doyle', 'Content', '##s', 'I', '.', 'A', 'Sc', '##anda', '##l', 'in', 'Bohemia', 'II', '.', 'The', 'Red', '-', 'Head', '##ed', 'League', 'III', '.', 'A', 'Case', 'of', 'Identity', 'IV', '.', 'The', 'Bo', '##sco', '##mbe', 'Valley', 'Mystery', 'V', '.', 'The', 'Five', 'Orange', 'Pi', '##ps', 'VI', '.', 'The', 'Man', 'with', 'the', 'T', '##wi', '##sted', 'Li', '##p', 'VII', '.', 'The', 'Adventure', 'of', 'the', 'Blue', 'Car', '##bu', '##nc', '##le', 'VIII', '.', 'The', 'Adventure', 'of', 'the', 'S', '##pec', '##kled', 'Band', 'IX', '.', 'The', 'Adventure', 'of', 'the', 'Engineer', '##â', '##s', 'T', '##hum', '##b', 'X', '.', 'The', 'Adventure', 'of', 'the', 'Noble', 'Bachelor', 'XI', '.', 'The', 'Adventure', 'of', 'the', 'Be', '##ryl', 'Co', '##rone', '##t', 'XII', '.', 'The', 'Adventure', 'of', 'the', 'Copper', 'Bee', '##ches', 'I', '.', 'A', 'SC', '##AN', '##DA', '##L', 'IN', 'B', '##OH', '##EM', '##IA', 'I', '.', 'To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_', 'the', '_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.', 'In', 'his', 'eyes', 'she', 'eclipse', '##s', 'and', 'pre', '##dom', '##inate', '##s', 'the', 'whole', 'of', 'her', 'sex', '.', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'and', 'that', 'one', 'particularly', ',', 'were', 'a', '##b', '##hor', '##rent', 'to', 'his', 'cold', ',', 'precise', 'but', 'ad', '##mir', '##ably', 'balanced', 'mind', '.', 'He', 'was', ',', 'I', 'take', 'it', ',', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen', ',', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position', '.', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passion', '##s', ',', 'save', 'with', 'a', 'g', '##ibe', 'and', 'a', 's', '##neer', '.', 'They', 'were', 'ad', '##mir', '##able', 'things', 'for', 'the', 'observer', '##â', '##ex', '##cell', '##ent', 'for', 'drawing', 'the', 'veil', 'from', 'men', '##â', '##s', 'motives', 'and', 'actions', '.', 'But', 'for', 'the', 'trained', 'reason', '##er', 'to', 'admit', 'such', 'in', '##trusion', '##s', 'into', 'his', 'own', 'delicate', 'and', 'finely', 'adjusted', 'temper', '##ament', 'was', 'to', 'introduce', 'a', 'distract', '##ing', 'factor', 'which', 'might', 'throw', 'a', 'doubt', 'upon', 'all', 'his', 'mental', 'results', '.', 'G', '##rit', 'in', 'a', 'sensitive', 'instrument', ',', 'or', 'a', 'crack', 'in', 'one', 'of', 'his', 'own', 'high', '-', 'power', 'lenses', ',', 'would', 'not', 'be', 'more', 'disturbing', 'than', 'a', 'strong', 'emotion', 'in', 'a', 'nature', 'such', 'as', 'his', '.', 'And', 'yet', 'there', 'was', 'but', 'one', 'woman', 'to', 'him', ',', 'and', 'that', 'woman', 'was', 'the', 'late', 'Irene', 'Adler', ',', 'of', 'dubious', 'and', 'questionable', 'memory', '.', 'I', 'had', 'seen', 'little', 'of', 'Holmes', 'lately', '.', 'My', 'marriage', 'had', 'drifted', 'us', 'away', 'from', 'each', 'other', '.', 'My', 'own', 'complete', 'happiness', ',', 'and', 'the', 'home', '-', 'centred', 'interests', 'which', 'rise', 'up', 'around', 'the', 'man', 'who', 'first', 'finds', 'himself', 'master', 'of', 'his', 'own', 'establishment', ',', 'were', 'sufficient', 'to', 'absorb', 'all', 'my', 'attention', ',', 'while', 'Holmes', ',', 'who', 'lo', '##athed', 'every', 'form', 'of', 'society', 'with', 'his', 'whole', 'Bohemian', 'soul', ',', 'remained', 'in', 'our', 'lo', '##dging', '##s', 'in', 'Baker', 'Street', ',', 'buried', 'among', 'his', 'old', 'books', ',', 'and', 'alternating', 'from', 'week', 'to', 'week', 'between', 'cocaine', 'and', 'ambition', ',', 'the', 'd', '##rows', '##iness', 'of', 'the', 'drug', ',', 'and', 'the', 'fierce', 'energy', 'of', 'his', 'own', 'keen', 'nature', '.', 'He', 'was', 'still', ',', 'as', 'ever', ',', 'deeply', 'attracted', 'by', 'the', 'study', 'of', 'crime', ',', 'and', 'occupied', 'his', 'immense', 'faculties', 'and', 'extraordinary', 'powers', 'of', 'observation', 'in', 'following', 'out', 'those', 'clues', ',', 'and', 'clearing', 'up', 'those', 'mysteries', 'which', 'had', 'been', 'abandoned', 'as', 'hopeless', 'by', 'the', 'official', 'police', '.', 'From', 'time', 'to', 'time', 'I', 'heard', 'some', 'vague', 'account', 'of', 'his', 'doing', '##s', ':', 'of', 'his', 'summon', '##s', 'to', 'Odessa', 'in', 'the', 'case', 'of', 'the', 'T', '##re', '##po', '##ff', 'murder', ',', 'of', 'his', 'clearing', 'up', 'of', 'the', 'singular', 'tragedy', 'of', 'the', 'Atkinson', 'brothers', 'at', 'Tri', '##nco', '##mal', '##ee', ',', 'and', 'finally', 'of', 'the', 'mission', 'which', 'he', 'had', 'accomplished', 'so', 'delicate', '##ly', 'and', 'successfully', 'for', 'the', 'reigning', 'family', 'of', 'Holland', '.', 'Beyond', 'these', 'signs', 'of', 'his', 'activity', ',', 'however', ',', 'which', 'I', 'merely', 'shared', 'with', 'all', 'the', 'readers', 'of', 'the', 'daily', 'press', ',', 'I', 'knew', 'little', 'of', 'my', 'former', 'friend', 'and', 'companion', '.', 'One', 'night', '##â', '##it', 'was', 'on', 'the', 'twentieth', 'of', 'March', ',', '1888', '##â', '##I', 'was', 'returning', 'from', 'a', 'journey', 'to', 'a', 'patient', '(', 'for', 'I', 'had', 'now', 'returned', 'to', 'civil', 'practice', ')', ',', 'when', 'my', 'way', 'led', 'me', 'through', 'Baker', 'Street', '.', 'As', 'I', 'passed', 'the', 'well', '-', 'remembered', 'door', ',', 'which', 'must', 'always', 'be', 'associated', 'in', 'my', 'mind', 'with', 'my', 'w', '##oo', '##ing', ',', 'and', 'with', 'the', 'dark', 'incidents', 'of', 'the', 'Study', 'in', 'Scarlet', ',', 'I', 'was', 'seized', 'with', 'a', 'keen', 'desire', 'to', 'see', 'Holmes', 'again', ',', 'and', 'to', 'know', 'how', 'he', 'was', 'employing', 'his', 'extraordinary', 'powers', '.', 'His', 'rooms', 'were', 'brilliant', '##ly', 'lit', ',', 'and', ',', 'even', 'as', 'I', 'looked', 'up', ',', 'I', 'saw', 'his']\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "response = requests.get(\"https://www.gutenberg.org/files/1661/1661-0.txt\")\n",
        "sherlock_raw_text = response.text\n",
        "\n",
        "sherlock_hf_tokens = tokenizer.tokenize( sherlock_raw_text )\n",
        "print(sherlock_hf_tokens[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdzHA6EqdWrf"
      },
      "source": [
        "## Byte-Pair Encoding\n",
        "\n",
        "Algorithm Idea:\n",
        "1. Pretokenize all of the things separated by whitespace, etc. (like we've done previously)\n",
        "2. Start with a *vocabulary* containing all the individual characters from the pre-tokens\n",
        "3. Until the vocabulary is the desired size\n",
        "    * merge together the most frequently-appearing pair of tokens and add it as a new token to the *vocabulary*\n",
        "    \n",
        "    \n",
        "Let's go through the example from here: https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt\n",
        "\n",
        "Assume the corpus has only the following words: \"hug\", \"pug\", \"pun\", \"bun\", \"hugs\" and they appear with these frequencies (meaning \"hug\" appears 10 times, \"pug\" appears 5 times, etc:\n",
        "\n",
        "(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1LcQfCRdWrf"
      },
      "source": [
        "The initial vocabulary will be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRP_vHwndWrf",
        "outputId": "eb80cdfa-b114-424b-b2c3-57e74eae953c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj-L8xI9dWrf"
      },
      "source": [
        "Tokenize our pre-tokens using this vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p41_GA3-dWrf",
        "outputId": "c84b0e21-3f1b-45e3-d12b-7bddf700bdf5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "corpus = [(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2dBqLgVdWrf"
      },
      "source": [
        "Find how frequently each pair appears.\n",
        "\n",
        "* \"h\" \"u\" appears 15 times (10 from \"hug\", 5 from \"hugs\")\n",
        "* \"u\" \"g\" appears 20 times (10 from \"hug\", 5 from \"pug\", 5 from \"hugs\")\n",
        "* \"p\" \"u\" appears __ times (exercise)\n",
        "* \"u\" \"n\" appears __ times (exercise)\n",
        "* \"b\" \"u\" appears __ times (exercise)\n",
        "* \"g\" \"s\" appears __ times (exercise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBilu0zgdWrf"
      },
      "source": [
        "If \"u\" \"g\" is the most frequent, we then add it to our vocabulary.\n",
        "\n",
        "Vocabulary and corpus are now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRiuTvCAdWrf",
        "outputId": "42c2eff6-2e45-467a-b330-ef51303ec2ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\"]\n",
        "corpus = [(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42jWR4wgdWrf"
      },
      "source": [
        "Finding pair frequencies\n",
        "\n",
        "* \"h\" \"ug\" appears 15 times (10 from \"hug\", 5 from \"hugs\")\n",
        "* \"p\" \"ug\" appears 5 times\n",
        "* \"p\" \"u\"  appears 12 times\n",
        "* \"u\" \"n\"  appears 16 times\n",
        "* \"b\" \"u\"  appears 4 times\n",
        "* \"ug\" \"s\" appears 5 times\n",
        "\n",
        "So we merge \"u\" \"n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83py4d5wdWrf",
        "outputId": "f93a680b-7144-40fc-ab44-b2ffcb1352c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\"]\n",
        "corpus = [(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"h\" \"ug\" \"s\", 5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va6c9d0odWrj"
      },
      "source": [
        "Finding pair frequencies\n",
        "\n",
        "* \"h\" \"ug\" appears 15 times\n",
        "* \"p\" \"ug\" appears 5 times\n",
        "* \"p\" \"un\"  appears 12 times\n",
        "* \"b\" \"un\"  appears 4 times\n",
        "* \"ug\" \"s\" appears 5 times\n",
        "\n",
        "So we merge \"h\" \"ug\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOHKmNQMdWrj",
        "outputId": "3b107f7e-3470-4cd6-f112-184bb28bccaa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]\n",
        "corpus = [(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzN1hnuSdWrj"
      },
      "source": [
        "**Exercise:** when happens on the next merge step?\n",
        "\n",
        "Remember - we stop when the vocabular hits a pre-determined size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzN_YzLHdWrj"
      },
      "source": [
        "## Tokenizing with BPE\n",
        "\n",
        "The algorithm for tokenizing with this trained model (vocabulary) is\n",
        "\n",
        "1. pre-tokenize (split by spaces)\n",
        "2. split pre-tokens (words) into characters, use \"[UNK]\" for unknowns\n",
        "3. apply the merge rules that were learned *in order*\n",
        "\n",
        "In our example, we learned the rules\n",
        "* (\"u\", \"g\") -> \"ug\"\n",
        "* (\"u\", \"n\") -> \"un\"\n",
        "* (\"h\", \"ug\") -> \"hug\"\n",
        "\n",
        "Example text: \"pun bug hugs mug\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLIvgussdWrj",
        "outputId": "8e829bb2-9e7f-4843-d62e-8abfbb722f4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]\n",
        "pre_tokens = [\"pun\",\"bug\",\"hugs\",\"mug\"]\n",
        "split_pre_tokens = [[\"p\",\"u\",\"n\"],[\"b\",\"u\",\"g\"],[\"h\",\"u\",\"g\",\"s\"],[\"m\",\"u\",\"g\"]]\n",
        "split_pre_tokens = [[\"p\",\"u\",\"n\"],[\"b\",\"u\",\"g\"],[\"h\",\"u\",\"g\",\"s\"],[\"[UNK]\",\"u\",\"g\"]] #there is no m in the vocabulary\n",
        "after_first_merge_rule = [[\"p\",\"u\",\"n\"],[\"b\",\"ug\"],[\"h\",\"ug\",\"s\"],[\"[UNK]\",\"ug\"]]\n",
        "after_second_merge_rule = [[\"p\",\"un\"],[\"b\",\"ug\"],[\"h\",\"ug\",\"s\"],[\"[UNK]\",\"ug\"]]\n",
        "after_third_merge_rule = [[\"p\",\"un\"],[\"b\",\"ug\"],[\"hug\",\"s\"],[\"[UNK]\",\"ug\"]]\n",
        "final_tokens = [\"p\",\"un\",\"b\",\"ug\",\"hug\",\"s\",\"[UNK]\",\"ug\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d70UVyPVdWrj"
      },
      "source": [
        "## WordPiece Tokenization\n",
        "\n",
        "Similar to BPE but represents partial words with \"##\", so instead of"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVF0ZT_TdWrk",
        "outputId": "dcb3a74f-8754-4e12-ffa6-a12311a1af1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "corpus = [(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftWDZsHudWrk"
      },
      "source": [
        "you have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TraETRBqdWrk",
        "outputId": "e541ab0c-c1ce-463b-bda1-da83d5342aa4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "corpus = (\"h\" \"##u\" \"##g\", 10), (\"p\" \"##u\" \"##g\", 5), (\"p\" \"##u\" \"##n\", 12), (\"b\" \"##u\" \"##n\", 4), (\"h\" \"##u\" \"##g\" \"##s\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfbvTLEdWrk"
      },
      "source": [
        "and it uses a different method to choose which pair to merge:\n",
        "\n",
        "$$score=(\\mbox{freq_of_pair})/(\\mbox{freq_of_first_element}\\times \\mbox{freq_of_second_element})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2-lffVUdWrk",
        "outputId": "478afc65-58e1-48d4-aa2e-17df11b14b7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "initial_vocabulary = [\"b\", \"h\", \"p\", \"##g\", \"##n\", \"##s\", \"##u\"]\n",
        "corpus = (\"h\" \"##u\" \"##g\", 10), (\"p\" \"##u\" \"##g\", 5), (\"p\" \"##u\" \"##n\", 12), (\"b\" \"##u\" \"##n\", 4), (\"h\" \"##u\" \"##g\" \"##s\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiJfQjuPdWrk"
      },
      "source": [
        "### scoring (\"##u\", \"##g\") -> \"##ug\" rule\n",
        "* (\"##u\", \"##g\") is present 20 times\n",
        "* \"##u\" appears 36 times\n",
        "* \"##g\" appears 20 times\n",
        "\n",
        "Score: $20/(36*20) = 1/36$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MrPAfqUdWrk"
      },
      "source": [
        "### scoring (\"h\", \"##u\") -> \"hu\" rule\n",
        "* (\"h\", \"##u\") is present 15 times\n",
        "* \"h\" appears 15 times\n",
        "* \"##u\" appears 36 times\n",
        "\n",
        "Score: $15/(15*36) = 1/36$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdn3HUtzdWrk"
      },
      "source": [
        "### scoring (\"##g\", \"##s\") -> \"##gs\" rule\n",
        "* (\"##g\", \"##s\") is present 5 times\n",
        "* \"##g\" appears 20 times\n",
        "* \"##s\" appears 5 times\n",
        "\n",
        "Score: $5/(20*5) = 1/20$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYQFzH6wdWrk"
      },
      "source": [
        "among these three rules, (\"##g\", \"##s\") -> \"##gs\" would be chosen\n",
        "\n",
        "**Take-away:** WordPiece prioritizes merges in which the individual parts are less-frequent\n",
        "* the pairing represents a bigger portion of the occurrences of the sub-tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krwBfWDrdWrk"
      },
      "source": [
        "**Exercise:** How would (\"##u\", \"##n\") -> \"##un\" score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q6Iy6sTdWrk"
      },
      "source": [
        "## Applied Exploration\n",
        "\n",
        "Find some new text, tokenize it according to one or more of the methods discussed here\n",
        "\n",
        "Use it as input for the Markov Chain in the previous set of notes\n",
        "\n",
        "Describe what you did and record notes about your results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9DxconLdWrk"
      },
      "source": [
        "## Extended Implementation Idea\n",
        "\n",
        "Write the code that will do BPE or WordPiece automatically\n",
        "\n",
        "Both the BPE and WordPiece have examples in the Hugging Face course\n",
        "* https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt\n",
        "* https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt\n",
        "\n",
        "Except: they use Hugging Face tokenizers for the pre-tokenization. You should do it using `split()` like we did above. Because of the way that it groups tokens, I don't think you should have to worry about separating out punctuation, just include it in your vocabulary."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}