{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/blob/main/F6_2_RecurrentNeuralNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## Recurrent Neural Networks\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F6_2_RecurrentNeuralNetworks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XG5ehZQ_wdx"
      },
      "source": [
        "## Announcement Update\n",
        "\n",
        "AI - English Faculty Candidate: Gabriel Ford\n",
        "\n",
        "Scholarly Presentation: Friday at 9:00am in Howard 309"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6ugvUJo_wdx"
      },
      "source": [
        "## Reference\n",
        "\n",
        "SLP: RNNs and LSTMs, Chapter 9 of Speech and Language Processing by Daniel Jurafsky & James H. Martin https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
        "\n",
        "Keras documentation for SimpleRNN Layer: https://keras.io/api/layers/recurrent_layers/simple_rnn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNbRxLwy_wdy",
        "outputId": "0706a96c-2a76-4c88-fb03-efd9c04579b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Installing collected packages: safetensors, dill, multiprocess, huggingface-hub, tokenizers, transformers, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install datasets keras tensorflow transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAeG3RE1_wdy"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)\n",
        "\n",
        "A **recurrent neural network** is a neural network with a loop inside of it - some of the outputs in one layer become inputs of the same or an earlier layer\n",
        "\n",
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/RNN_highlevel.png?raw=1\">\n",
        "</div>\n",
        "\n",
        "* $x_{t}$: neural network input at time $t$\n",
        "* $h_{t}$: hidden layer state at time $t$\n",
        "* $y_{t}$: output layer state at time $t$\n",
        "\n",
        "*Allows information from past inputs to affect current predictions*\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.1, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLRwXNLB_wdz"
      },
      "source": [
        "## RNN visualized as a feedforward network\n",
        "\n",
        "In this image, the inputs are shown on bottom and the outputs on top\n",
        "\n",
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/RNN_as_feedforward.png?raw=1\" width=400>\n",
        "</div>\n",
        "\n",
        "* $h_{t-1}$: hidden layer state at time $t-1$ is an input to $h_{t}$\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.2, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyGGRyF9_wdz"
      },
      "source": [
        "## RNN \"unrolled\" in time\n",
        "\n",
        "Later outputs continue to be influenced by the entire sequence\n",
        "\n",
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/RNN_unroll.png?raw=1\" width=500>\n",
        "</div>\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.4, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlR7oiPA_wdz"
      },
      "source": [
        "## Coding up a simple RNN in Keras\n",
        "\n",
        "Defining a Recurrent layer is similar to defining a Dense layer\n",
        "\n",
        "`return_sequences=False` for now, we don't want to return the entire sequence, just the last output\n",
        "\n",
        "`stateful=False` allows the state from one **batch** to carry over to the next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Debjn3so_wdz"
      },
      "outputs": [],
      "source": [
        "# A feedforward network with one hidden layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=50, input_length=sequence_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation=\"relu\"))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "# A recurrent network with one layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=50, input_length=sequence_length))\n",
        "model.add(SimpleRNN(100,return_sequences=False,stateful=False))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDR9KhaQ_wd0"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Copy in your code from the non-recurrent neural language model from last time, and replace the Flatten+Dense layer with a SimpleRNN layer like above.\n",
        "* Use the same dataset, `ag_news`, prepared in the same way\n",
        "* Run it with small enough subset to train within a few minutes\n",
        "\n",
        "How do the performances compare?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MEDUYFPDOJj",
        "outputId": "78dfb3ef-b470-4944-dc8b-6235ad592505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 5226\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 8s 32ms/step - loss: 8.3046 - accuracy: 0.0441\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 2s 18ms/step - loss: 6.8191 - accuracy: 0.0486\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 6.5001 - accuracy: 0.0510\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 1s 10ms/step - loss: 6.3328 - accuracy: 0.0571\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 6.1701 - accuracy: 0.0605\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 5.9734 - accuracy: 0.0621\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 5.7244 - accuracy: 0.0762\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 5.4301 - accuracy: 0.0998\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 5.1199 - accuracy: 0.1186\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 4.7990 - accuracy: 0.1590\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4160 - accuracy: 0.2189\n",
            "Test accuracy: 21.89%\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten, SimpleRNN ,GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "data = load_dataset(\"ag_news\")\n",
        "\n",
        "data_subset, _ = train_test_split(data[\"train\"][\"text\"],train_size=500)\n",
        "train_data, test_data = train_test_split(data_subset,train_size=0.8)\n",
        "\n",
        "# Prepare the tokenizer and fit on the training text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data_subset)\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary size:\",vocabulary_size)\n",
        "\n",
        "sequence_length = 1\n",
        "\n",
        "def process_data(data,sequence,tokenizer):\n",
        "\n",
        "  texts = tokenizer.texts_to_sequences(test_data)\n",
        "  vocabulary_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # Create the sequences\n",
        "  predictor_sequences = []\n",
        "  targets = []\n",
        "  for text in texts:\n",
        "      for i in range(sequence_length, len(text)):\n",
        "          # Take the sequence of tokens as input and the next token as target\n",
        "          curr_target = text[i]\n",
        "          curr_predictor_sequence = text[i-sequence_length:i]\n",
        "          predictor_sequences.append(curr_predictor_sequence)\n",
        "          targets.append(curr_target)\n",
        "\n",
        "  # Pad sequences to ensure uniform length\n",
        "  predictor_sequences_padded = pad_sequences(predictor_sequences, maxlen=sequence_length, padding='pre')\n",
        "\n",
        "  # Convert target to one-hot encoding\n",
        "  target_word_one_hot = to_categorical(targets, num_classes=vocabulary_size)\n",
        "\n",
        "  return predictor_sequences_padded, target_word_one_hot\n",
        "\n",
        "predictor_sequences_padded, target_word_one_hot = process_data(train_data, sequence_length, tokenizer)\n",
        "predictor_sequences_padded_test, target_word_one_hot_test = process_data(test_data,  sequence_length, tokenizer)\n",
        "\n",
        "# A recurrent network with one layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=50, input_length=sequence_length))\n",
        "model.add(SimpleRNN(100,return_sequences=False,stateful=False))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(predictor_sequences_padded, target_word_one_hot, epochs=10, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(predictor_sequences_padded_test, target_word_one_hot_test)\n",
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg3C8GBH_wd0"
      },
      "source": [
        "## Reducing your context window\n",
        "\n",
        "Because of the sequential nature of the RNN layer, you don't need to pass in as big of a context window.\n",
        "\n",
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/RNN_context_simplification.png?raw=1\" width=500>\n",
        "</div>\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.5, https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93vD4xI__wd0"
      },
      "source": [
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/RNN_languagemodeling.png?raw=1\" width=700>\n",
        "</div>\n",
        "\n",
        "### Exercise\n",
        "\n",
        "Reduce your `sequence_length` to 1. Train and test again.\n",
        "\n",
        "How do the results compare?\n",
        "\n",
        "\n",
        "image source: SLP Fig. 9.6, https://web.stanford.edu/~jurafsky/slp3/9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQSPXwe4_wd0"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Our Keras RNN-based neural language model doesn't do a great job of generating text\n",
        "\n",
        "### Exercise:\n",
        "\n",
        "Try it with this text generation code from last time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn3TElS9_wd0",
        "outputId": "62634df3-8444-4bbc-b2ee-0c8e8b54b186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "world 39 s largest said and german the world 39 s largest said and german the world 39 s largest said and german the world 39 s largest said and german the world 39 s largest said and german the world 39 s largest said and german the world 39 "
          ]
        }
      ],
      "source": [
        "starter_string = \"the\"\n",
        "tokens_list = tokenizer.texts_to_sequences([starter_string])\n",
        "tokens = tokens_list[0]\n",
        "\n",
        "for i in range(50):\n",
        "    curr_seq = tokens[-sequence_length:]\n",
        "    curr_array = np.array([curr_seq])\n",
        "    predicted_probabilities = model.predict(curr_array,verbose=0)\n",
        "    predicted_index = np.argmax(predicted_probabilities)\n",
        "    predicted_word = tokenizer.index_word[predicted_index]\n",
        "    print(predicted_word+\" \",end=\"\")\n",
        "    tokens.append(predicted_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYLtGLKy_wd1"
      },
      "source": [
        "**One problem:** Keras will reset the state every time you make a call to `model.predict` so we lose the benefit of recurrence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHyZIgcm_wd1"
      },
      "source": [
        "## Exerting more control over when the state gets reset\n",
        "\n",
        "If your model uses the `stateful=True` parameter on the recurrent layer, you get more control over when to reset the state.\n",
        "* Downside: it's more of a pain to train the network like that\n",
        "\n",
        "*A workaround:* create another model with the same architecture except for `stateful` and copy the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mEWfBmsb_wd1"
      },
      "outputs": [],
      "source": [
        "# Create a new model with the same architecture but with stateful RNNs\n",
        "stateful_model = Sequential()\n",
        "stateful_model.add(Embedding(input_dim=vocabulary_size, output_dim=50, batch_input_shape=(1, sequence_length))) #batch size of 1\n",
        "stateful_model.add(SimpleRNN(100,return_sequences=False,stateful=True))\n",
        "stateful_model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "# Load the weights from your trained model\n",
        "stateful_model.set_weights(model.get_weights())\n",
        "\n",
        "# Compile the stateful model (required to make predictions)\n",
        "stateful_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7xg1XAp_wd1",
        "outputId": "9be9040d-9a8c-4468-a0e8-cd4dda04966b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "world 39 s largest ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap ap "
          ]
        }
      ],
      "source": [
        "starter_string = \"the\"\n",
        "tokens_list = tokenizer.texts_to_sequences([starter_string])\n",
        "tokens = tokens_list[0]\n",
        "\n",
        "#do this anytime you want to reset the states - for generating a brand new sequence\n",
        "stateful_model.reset_states()\n",
        "\n",
        "for i in range(50):\n",
        "    curr_seq = tokens[-sequence_length:]\n",
        "    curr_array = np.array([curr_seq])\n",
        "    predicted_probabilities = stateful_model.predict(curr_array,verbose=0)\n",
        "    predicted_index = np.argmax(predicted_probabilities)\n",
        "    predicted_word = tokenizer.index_word[predicted_index]\n",
        "    print(predicted_word+\" \",end=\"\")\n",
        "    tokens.append(predicted_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgA3zPWm_wd1"
      },
      "source": [
        "## Training a stateful model\n",
        "\n",
        "Keras makes you work a little harder if you want to train a stateful model from the start\n",
        "* Organize your sequences into batches\n",
        "* All batches need to be the same size (say 32 or 64)\n",
        "\n",
        "Might be appropriate if\n",
        "* You have several long documents\n",
        "* Each document takes multiple batches\n",
        "* You *don't* want to reset states between batches\n",
        "* You *do* want to reset states between documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6OAGzMq_wd1"
      },
      "source": [
        "## Throwback to a data set we worked with previously\n",
        "\n",
        "This example is going to do a couple of things\n",
        "* use The Adventures of Sherlock Holmes corpus we download from Project Gutenberg\n",
        "* use the WordPiece tokenizer from Hugging Face\n",
        "    * I want to keep around things like punctuation which gets removed by the Keras tokenizer\n",
        "    * I want to show you how you can mix different tokenizers with Keras models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308,
          "referenced_widgets": [
            "48ef04fa851046c9b3792e0d0ee0aa82",
            "e860a66d8e204f65ad64eb4c52636a2c",
            "21cea462619e49e09c349da0bb058785",
            "f94487c0b3db4e9a857ba09f737db194",
            "2e48a2b086e14e51beb242043e5af334",
            "03917244fb16448ab22feedb46647f49",
            "bf7461ae65574bdca8b899a177f36af8",
            "6b0a9662e7b94a37a3b59962195815ae",
            "4707d9017a9941ac84491a437c04a8de",
            "1e9994549c5d497ca03726edb40a8bd7",
            "a0b964c317fc45869de1b9866fe32d46",
            "960df2e1f22d48c1878f1316d1374406",
            "ddb591cf6b284b569fcf7189f9fc1ec5",
            "a6b56e4637b4410fb0b3e8f382f4f195",
            "f700ac13fbff41b5aa81952b78bc44fe",
            "e60f504300604a41b61bc8a5b1a4df0d",
            "e50bde5532174363b6b88687d501cc0d",
            "cbcab3c4e4dd4ecf9acb27ddac1bf5d4",
            "dccc06daa91842f29c8b7b8332370a6f",
            "faf0bacebb594dfaa6be2298a76d7aa6",
            "ac5cf129eac140a184fecaa2448b3ddd",
            "7d00a33aaa6e46d0851251d77c9e0617",
            "ab81d8c7fd864de1acca9d3d95716730",
            "9be92d0916cc48598e3502120676a006",
            "9fd1a3f46775482aa87f9d58c49b01f9",
            "37c29480b7ab4f25ab3f071d587c0257",
            "50e5555fc78b4458aa1fc9fdd3ce9eb0",
            "dbfc91f4e35245a8b679c8f82a059b5c",
            "84745a16d2f74723ae4339906556b953",
            "fb8c175cee654799a19fc9328fe01b92",
            "00318946f2414a06866dee2cb0d16506",
            "0f53fedebcfd4dfea55c7020b062df41",
            "ccfac25ea76d4b2dac2d40315ed4f653",
            "82fdcbca094a4887aab6a76b197c77cd",
            "212ea3d6da3d412e830f95a9be951b89",
            "eea8bd81a10c4d618a6f843e6f05d596",
            "9ffdc37b87fa4e81844da44ccb962223",
            "6f564e4dd9f84b8881ccd6bf20513583",
            "0b7370c62d584e70b58a2636903d9477",
            "2243c2b45bf04a33b3321e6083bbc2f0",
            "503ba7e9e8a248b19190001803e75471",
            "af33f8977f034b92b86e9f725bc2b952",
            "a566ea9718f54092880e76538bfa8005",
            "5f2edd141e294805ab11631bf94fc9b2"
          ]
        },
        "id": "RD6iI5g4_wd1",
        "outputId": "39302864-1b5b-40b5-a641-a3ff454a10b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48ef04fa851046c9b3792e0d0ee0aa82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "960df2e1f22d48c1878f1316d1374406",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab81d8c7fd864de1acca9d3d95716730",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82fdcbca094a4887aab6a76b197c77cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (143245 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a sample of the tokenized text:\n",
            "['tall', ',', 'spare', 'figure', 'pass', 'twice', 'in', 'a', 'dark', 'silhouette', 'against', 'the', 'blind', '.', 'He', 'was', 'pacing', 'the', 'room', 'swiftly']\n",
            "\n",
            "Here's the text's ids\n",
            "[3543, 117, 8608, 2482, 2789, 3059, 1107, 170, 1843, 27316, 1222, 1103, 7198, 119, 1124, 1108, 17218, 1103, 1395, 12476]\n",
            "Vocabulary size:\n",
            "28996\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "response = requests.get(\"https://www.gutenberg.org/files/1661/1661-0.txt\")\n",
        "sherlock_raw_text = response.text\n",
        "\n",
        "\n",
        "sherlock_tokens = tokenizer.tokenize( sherlock_raw_text )\n",
        "\n",
        "sherlock_tokens = sherlock_tokens[:10000] #let's limit the size of the text for this workshop\n",
        "\n",
        "print(\"Here's a sample of the tokenized text:\")\n",
        "print(sherlock_tokens[1000:1020])\n",
        "\n",
        "token_ids = tokenizer.convert_tokens_to_ids(sherlock_tokens )\n",
        "print(\"\\nHere's the text's ids\")\n",
        "print(token_ids[1000:1020])\n",
        "\n",
        "print(\"Vocabulary size:\")\n",
        "print(len(tokenizer.vocab))\n",
        "vocabulary_size = len(tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjxlvbc-_wd1"
      },
      "source": [
        "### Preparing the list of predictor/target pairs like before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nbDHZg0N_wd1"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten, SimpleRNN\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import pad_sequences\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "sequence_length = 1\n",
        "batch_size = 32\n",
        "\n",
        "predictor_sequences = []\n",
        "targets = []\n",
        "for i in range(sequence_length, len(token_ids)):\n",
        "    # Take the sequence of tokens as input and the next token as target\n",
        "    curr_target = token_ids[i]\n",
        "    curr_predictor_sequence = token_ids[i-sequence_length:i]\n",
        "    predictor_sequences.append(curr_predictor_sequence)\n",
        "    targets.append(curr_target)\n",
        "\n",
        "# Convert target to one-hot encoding\n",
        "targets_one_hot = to_categorical(targets, num_classes=vocabulary_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8tHHIv_wd2"
      },
      "source": [
        "### Grouping the sequences into batches of 32\n",
        "\n",
        "This adds an extra dimension to our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdh27OQQ_wd2",
        "outputId": "a1ae1f3a-f3e6-4eb4-a526-c2a6dec669bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before batching\n",
            "[[ 261]\n",
            " [ 221]\n",
            " [ 225]\n",
            " ...\n",
            " [1103]\n",
            " [1402]\n",
            " [1167]]\n",
            "\n",
            "after batching\n",
            "[[[  261]\n",
            "  [  221]\n",
            "  [  225]\n",
            "  ...\n",
            "  [ 1329]\n",
            "  [ 1104]\n",
            "  [ 2256]]\n",
            "\n",
            " [[ 5456]\n",
            "  [ 1107]\n",
            "  [ 1103]\n",
            "  ...\n",
            "  [ 1283]\n",
            "  [ 1137]\n",
            "  [ 1231]]\n",
            "\n",
            " [[  118]\n",
            "  [ 1329]\n",
            "  [ 1122]\n",
            "  ...\n",
            "  [ 1409]\n",
            "  [ 1128]\n",
            "  [ 1132]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1332]\n",
            "  [  170]\n",
            "  [ 1590]\n",
            "  ...\n",
            "  [ 6150]\n",
            "  [ 1166]\n",
            "  [26703]]\n",
            "\n",
            " [[18623]\n",
            "  [  117]\n",
            "  [ 1105]\n",
            "  ...\n",
            "  [ 1106]\n",
            "  [ 1143]\n",
            "  [  117]]\n",
            "\n",
            " [[ 1105]\n",
            "  [ 1145]\n",
            "  [ 1107]\n",
            "  ...\n",
            "  [ 1122]\n",
            "  [ 1108]\n",
            "  [ 2330]]]\n"
          ]
        }
      ],
      "source": [
        "def put_into_batches(data,batch_size):\n",
        "    num_batches = (len(data) // batch_size)\n",
        "    batched_data = []\n",
        "    for batch_idx in range(num_batches):\n",
        "        curr_batch = data[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
        "        batched_data.append(curr_batch)\n",
        "    batched_data = np.array(batched_data)\n",
        "    return batched_data\n",
        "\n",
        "\n",
        "train_features_batched = put_into_batches(predictor_sequences,batch_size)\n",
        "train_targets_batched = put_into_batches(targets_one_hot,batch_size)\n",
        "\n",
        "print(\"before batching\")\n",
        "print(np.array(predictor_sequences))\n",
        "\n",
        "print(\"\\nafter batching\")\n",
        "print(train_features_batched)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XakWsVXq_wd2"
      },
      "source": [
        "## Creating and compiling the model\n",
        "\n",
        "Note that in this case, we set `batch_input_shape=(batch_size, sequence_length)`\n",
        "\n",
        "instead of `input_length=sequence_length`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xJnqy7TT_wd2"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=50, batch_input_shape=(batch_size, sequence_length)))\n",
        "model.add(SimpleRNN(100,return_sequences=False,stateful=True))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVBpxwX_wd2"
      },
      "source": [
        "## Writing a training loop\n",
        "\n",
        "instead of just doing `model.fit`, we'll do `model.train_on_batch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buzkYDYz_wd2",
        "outputId": "0ab21ad5-7c20-4f15-e948-440a9e0289a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 2/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 3/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 4/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 5/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 6/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 7/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 8/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 9/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n",
            "Epoch 10/10\n",
            "\tBatch 100/312\n",
            "\tBatch 200/312\n",
            "\tBatch 300/312\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10  # Number of epochs to train for\n",
        "number_of_batches = len(train_features_batched)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    model.reset_states()  # Reset states at the start of each epoch\n",
        "\n",
        "\n",
        "    for batch_idx in range(number_of_batches):\n",
        "        #print batch number every 1000 batches\n",
        "        if (batch_idx+1) % 100 == 0:\n",
        "            print(f'\\tBatch {batch_idx+1}/{number_of_batches}')\n",
        "\n",
        "        # Train on the batch\n",
        "        model.train_on_batch(train_features_batched[batch_idx], train_targets_batched[batch_idx])\n",
        "\n",
        "    # if you switch to a new document, do this\n",
        "    #model.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZexVTIq_wd2"
      },
      "source": [
        "### Now let's use our model to generate some text\n",
        "\n",
        "This code looks much different because we're using the Hugging Face tokenizer\n",
        "* turn text into ids with `tokenizer.encode`\n",
        "* turn ids into text with `tokenizer.decode`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSd2DN3m_wd2",
        "outputId": "57a579e9-ccd5-4447-f9bd-412aabbaa9ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the cry of the room, and I is the street. â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â â\n"
          ]
        }
      ],
      "source": [
        "starter_string = \"the\"\n",
        "\n",
        "# Encode the starter string to token IDs\n",
        "input_ids = tokenizer.encode(starter_string, add_special_tokens=False)\n",
        "\n",
        "for i in range(50):\n",
        "    # Get the last sequence_length tokens\n",
        "    curr_seq = input_ids[-sequence_length:]\n",
        "    # Predict the next token ID\n",
        "    predicted_probabilities = model.predict(np.array([curr_seq]), verbose=0)\n",
        "    predicted_index = np.argmax(predicted_probabilities, axis=-1)\n",
        "    # Add the predicted token ID to the sequence\n",
        "    input_ids.append(predicted_index[0])\n",
        "\n",
        "# Decode the token IDs to a string\n",
        "generated_sequence = tokenizer.decode(input_ids, clean_up_tokenization_spaces=True)\n",
        "print(generated_sequence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAyqhxzg_wd2"
      },
      "source": [
        "## Applied Exploration\n",
        "\n",
        "Adjust the code to get this working on more than one longer document\n",
        "* can get multiple Project Gutenberg texts\n",
        "* can use a Hugging Face dataset with longer texts (i.e., multiple sentences per entry, unlike `ag_news`)\n",
        "\n",
        "Let it train for a while and then generate some text\n",
        "* Did training with larger data sets improve the kind of text you were able to generate?\n",
        "* describe what you did and write up an interpretation of your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEJYotHMLpY8",
        "outputId": "9bd0f8d5-5c9d-441f-be03-721846baf60e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (316642 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a sample of the tokenized text:\n",
            "['tall', ',', 'spare', 'figure', 'pass', 'twice', 'in', 'a', 'dark', 'silhouette', 'against', 'the', 'blind', '.', 'He', 'was', 'pacing', 'the', 'room', 'swiftly']\n",
            "\n",
            "Here's the text's ids\n",
            "[3543, 117, 8608, 2482, 2789, 3059, 1107, 170, 1843, 27316, 1222, 1103, 7198, 119, 1124, 1108, 17218, 1103, 1395, 12476]\n",
            "Vocabulary size:\n",
            "28996\n",
            "before batching\n",
            "[[ 261  221  225 ... 1105 1114 1593]\n",
            " [ 221  225 1109 ... 1114 1593 1185]\n",
            " [ 225 1109 4042 ... 1593 1185 9118]\n",
            " ...\n",
            " [1104 1329 1106 ... 1720 1107 1103]\n",
            " [1329 1106 1143 ... 1107 1103 1402]\n",
            " [1106 1143  117 ... 1103 1402 1167]]\n",
            "\n",
            "after batching\n",
            "[[[  261   221   225 ...  1105  1114  1593]\n",
            "  [  221   225  1109 ...  1114  1593  1185]\n",
            "  [  225  1109  4042 ...  1593  1185  9118]\n",
            "  ...\n",
            "  [ 1329  1104  2256 ... 24689  1529  1114]\n",
            "  [ 1104  2256  5456 ...  1529  1114  1142]\n",
            "  [ 2256  5456  1107 ...  1114  1142   174]]\n",
            "\n",
            " [[ 5456  1107  1103 ...  1142   174  2064]\n",
            "  [ 1107  1103  1244 ...   174  2064  9753]\n",
            "  [ 1103  1244  1311 ...  2064  9753  1137]\n",
            "  ...\n",
            "  [ 1283  1137  1231 ...  1103  3892  1104]\n",
            "  [ 1137  1231   118 ...  3892  1104  1103]\n",
            "  [ 1231   118  1329 ...  1104  1103  1583]]\n",
            "\n",
            " [[  118  1329  1122 ...  1103  1583  1187]\n",
            "  [ 1329  1122  1223 ...  1583  1187  1128]\n",
            "  [ 1122  1223  1103 ...  1187  1128  1132]\n",
            "  ...\n",
            "  [ 1409  1128  1132 ...  1853   117  1617]\n",
            "  [ 1128  1132  1136 ...   117  1617   164]\n",
            "  [ 1132  1136  1388 ...  1617   164   174]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1134   146  6321 ...   248  3048  4064]\n",
            "  [  146  6321   119 ...  3048  4064  1225]\n",
            "  [ 6321   119  1135 ...  4064  1225  1115]\n",
            "  ...\n",
            "  [ 1111  1586   117 ... 14683  1110  1120]\n",
            "  [ 1586   117  1152 ...  1110  1120  1517]\n",
            "  [  117  1152  1127 ...  1120  1517  1106]]\n",
            "\n",
            " [[ 1152  1127 15957 ...  1517  1106  6274]\n",
            "  [ 1127 15957  1106 ...  1106  6274  1106]\n",
            "  [15957  1106  1501 ...  6274  1106  1103]\n",
            "  ...\n",
            "  [  118  1696   119 ...   119  1130  1103]\n",
            "  [ 1696   119  1332 ...  1130  1103  1692]\n",
            "  [  119  1332   170 ...  1103  1692  1104]]\n",
            "\n",
            " [[ 1332   170  1590 ...  1692  1104  1103]\n",
            "  [  170  1590  6191 ...  1104  1103 21410]\n",
            "  [ 1590  6191  1115 ...  1103 21410 12859]\n",
            "  ...\n",
            "  [ 6150  1166 26703 ...  1590 13707  1120]\n",
            "  [ 1166 26703 18623 ... 13707  1120  1123]\n",
            "  [26703 18623   117 ...  1120  1123  2963]]]\n",
            "Epoch 1/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 2/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 3/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 4/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 5/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 6/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 7/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 8/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 9/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "Epoch 10/10\n",
            "\tBatch 100/310\n",
            "\tBatch 200/310\n",
            "\tBatch 300/310\n",
            "the man of the street, and had be up. â âI was not be her. â âI was a cry of the street, and had be up and the street, and a cry of the street, and had be up and the street\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from transformers import AutoTokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load a larger dataset or multiple Project Gutenberg texts\n",
        "texts = []\n",
        "urls = [\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\",\n",
        "    \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
        "]\n",
        "\n",
        "# Loop trough all the urls\n",
        "for url in urls:\n",
        "    response = requests.get(url)\n",
        "    texts.append(response.text)\n",
        "\n",
        "# Combine all texts into one large text\n",
        "raw_text = \"\\n\".join(texts)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokens = tokenizer.tokenize(raw_text)\n",
        "tokens = tokens[:10000]  # Limit the size of the text for this example\n",
        "\n",
        "print(\"Here's a sample of the tokenized text:\")\n",
        "print(tokens[1000:1020])\n",
        "\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"\\nHere's the text's ids\")\n",
        "print(token_ids[1000:1020])\n",
        "\n",
        "print(\"Vocabulary size:\")\n",
        "print(len(tokenizer.vocab))\n",
        "vocabulary_size = len(tokenizer.vocab)\n",
        "\n",
        "sequence_length = 50  # Adjust the sequence length\n",
        "batch_size = 32\n",
        "\n",
        "predictor_sequences = []\n",
        "targets = []\n",
        "for i in range(sequence_length, len(token_ids)):\n",
        "    curr_target = token_ids[i]\n",
        "    curr_predictor_sequence = token_ids[i - sequence_length:i]\n",
        "    predictor_sequences.append(curr_predictor_sequence)\n",
        "    targets.append(curr_target)\n",
        "\n",
        "targets_one_hot = to_categorical(targets, num_classes=vocabulary_size)\n",
        "\n",
        "def put_into_batches(data, batch_size):\n",
        "    num_batches = (len(data) // batch_size)\n",
        "    batched_data = []\n",
        "    for batch_idx in range(num_batches):\n",
        "        curr_batch = data[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
        "        batched_data.append(curr_batch)\n",
        "    batched_data = np.array(batched_data)\n",
        "    return batched_data\n",
        "\n",
        "train_features_batched = put_into_batches(predictor_sequences, batch_size)\n",
        "train_targets_batched = put_into_batches(targets_one_hot, batch_size)\n",
        "\n",
        "print(\"before batching\")\n",
        "print(np.array(predictor_sequences))\n",
        "\n",
        "print(\"\\nafter batching\")\n",
        "print(train_features_batched)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocabulary_size, output_dim=50, batch_input_shape=(batch_size, sequence_length)))\n",
        "model.add(SimpleRNN(100, return_sequences=False, stateful=True))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 10\n",
        "number_of_batches = len(train_features_batched)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    model.reset_states()\n",
        "\n",
        "    for batch_idx in range(number_of_batches):\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f'\\tBatch {batch_idx + 1}/{number_of_batches}')\n",
        "\n",
        "        model.train_on_batch(train_features_batched[batch_idx], train_targets_batched[batch_idx])\n",
        "\n",
        "# Generate text\n",
        "starter_string = \"the\"\n",
        "input_ids = tokenizer.encode(starter_string, add_special_tokens=False)\n",
        "\n",
        "for i in range(50):\n",
        "    curr_seq = input_ids[-sequence_length:]\n",
        "    predicted_probabilities = model.predict(np.array([curr_seq]), verbose=0)\n",
        "    predicted_index = np.argmax(predicted_probabilities, axis=-1)\n",
        "    input_ids.append(predicted_index[0])\n",
        "\n",
        "generated_sequence = tokenizer.decode(input_ids, clean_up_tokenization_spaces=True)\n",
        "print(generated_sequence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYUTIvKNfji"
      },
      "source": [
        "## Applied Exploration Results\n",
        "\n",
        "I ran the training for 10 epochs on a combined dataset from multiple Project Gutenberg texts. However, I encountered an issue with the sequence length exceeding the model's maximum limit (316642 > 512), resulting in indexing errors. This suggests that my current approach might involve a dataset that is too large for the chosen BERT-based model or exceeds its maximum sequence length.\n",
        "\n",
        "### Did training with larger data sets improve the kind of text you were able to generate?\n",
        "\n",
        "I couldn't fully assess the impact of training with a larger dataset due to the mentioned error. The generated text output displayed repetitive and incoherent patterns, possibly influenced by the dataset size or model parameters.\n",
        "\n",
        "### Describe what you did and write up an interpretation of your results:\n",
        "\n",
        "#### Dataset Handling:\n",
        "\n",
        "I fetched texts from multiple Project Gutenberg URLs and combined them into one large text.\n",
        "The combined text was tokenized using the BERT tokenizer, and a subset was chosen for training.\n",
        "\n",
        "#### Model Training:\n",
        "\n",
        "I employed a simple RNN model with an embedding layer and compiled it with categorical crossentropy loss using the Adam optimizer.\n",
        "The training loop was executed for a specified number of epochs.\n",
        "#### Issues Encountered:\n",
        "\n",
        "Unfortunately, the error message indicated that the total tokenized sequence length exceeded the maximum allowed for the chosen BERT-based model (512 tokens).\n",
        "\n",
        "The generated text output displayed signs of repetitiveness and lack of coherence, possibly influenced by the dataset size or model parameters.\n",
        "Interpretation:\n",
        "\n",
        "The error suggests the necessity to either choose a model with a larger maximum sequence length or preprocess the text data by chunking it into smaller parts.\n",
        "The quality of the generated text seems suboptimal, highlighting the potential impact of training data, model architecture, and hyperparameters on the results.\n",
        "Next Steps:\n",
        "\n",
        "To address the error, I plan to adjust the sequence length and potentially split the dataset into smaller chunks.\n",
        "Experimentation with different model architectures, hyperparameters, and training datasets is essential for enhancing the quality of the generated text."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00318946f2414a06866dee2cb0d16506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03917244fb16448ab22feedb46647f49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b7370c62d584e70b58a2636903d9477": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f53fedebcfd4dfea55c7020b062df41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9994549c5d497ca03726edb40a8bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212ea3d6da3d412e830f95a9be951b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7370c62d584e70b58a2636903d9477",
            "placeholder": "​",
            "style": "IPY_MODEL_2243c2b45bf04a33b3321e6083bbc2f0",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "21cea462619e49e09c349da0bb058785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b0a9662e7b94a37a3b59962195815ae",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4707d9017a9941ac84491a437c04a8de",
            "value": 29
          }
        },
        "2243c2b45bf04a33b3321e6083bbc2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e48a2b086e14e51beb242043e5af334": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c29480b7ab4f25ab3f071d587c0257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f53fedebcfd4dfea55c7020b062df41",
            "placeholder": "​",
            "style": "IPY_MODEL_ccfac25ea76d4b2dac2d40315ed4f653",
            "value": " 213k/213k [00:00&lt;00:00, 4.37MB/s]"
          }
        },
        "4707d9017a9941ac84491a437c04a8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ef04fa851046c9b3792e0d0ee0aa82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e860a66d8e204f65ad64eb4c52636a2c",
              "IPY_MODEL_21cea462619e49e09c349da0bb058785",
              "IPY_MODEL_f94487c0b3db4e9a857ba09f737db194"
            ],
            "layout": "IPY_MODEL_2e48a2b086e14e51beb242043e5af334"
          }
        },
        "503ba7e9e8a248b19190001803e75471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e5555fc78b4458aa1fc9fdd3ce9eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2edd141e294805ab11631bf94fc9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b0a9662e7b94a37a3b59962195815ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f564e4dd9f84b8881ccd6bf20513583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d00a33aaa6e46d0851251d77c9e0617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82fdcbca094a4887aab6a76b197c77cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_212ea3d6da3d412e830f95a9be951b89",
              "IPY_MODEL_eea8bd81a10c4d618a6f843e6f05d596",
              "IPY_MODEL_9ffdc37b87fa4e81844da44ccb962223"
            ],
            "layout": "IPY_MODEL_6f564e4dd9f84b8881ccd6bf20513583"
          }
        },
        "84745a16d2f74723ae4339906556b953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "960df2e1f22d48c1878f1316d1374406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb591cf6b284b569fcf7189f9fc1ec5",
              "IPY_MODEL_a6b56e4637b4410fb0b3e8f382f4f195",
              "IPY_MODEL_f700ac13fbff41b5aa81952b78bc44fe"
            ],
            "layout": "IPY_MODEL_e60f504300604a41b61bc8a5b1a4df0d"
          }
        },
        "9be92d0916cc48598e3502120676a006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbfc91f4e35245a8b679c8f82a059b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_84745a16d2f74723ae4339906556b953",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "9fd1a3f46775482aa87f9d58c49b01f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb8c175cee654799a19fc9328fe01b92",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00318946f2414a06866dee2cb0d16506",
            "value": 213450
          }
        },
        "9ffdc37b87fa4e81844da44ccb962223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a566ea9718f54092880e76538bfa8005",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2edd141e294805ab11631bf94fc9b2",
            "value": " 436k/436k [00:00&lt;00:00, 9.41MB/s]"
          }
        },
        "a0b964c317fc45869de1b9866fe32d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a566ea9718f54092880e76538bfa8005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b56e4637b4410fb0b3e8f382f4f195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dccc06daa91842f29c8b7b8332370a6f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf0bacebb594dfaa6be2298a76d7aa6",
            "value": 570
          }
        },
        "ab81d8c7fd864de1acca9d3d95716730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9be92d0916cc48598e3502120676a006",
              "IPY_MODEL_9fd1a3f46775482aa87f9d58c49b01f9",
              "IPY_MODEL_37c29480b7ab4f25ab3f071d587c0257"
            ],
            "layout": "IPY_MODEL_50e5555fc78b4458aa1fc9fdd3ce9eb0"
          }
        },
        "ac5cf129eac140a184fecaa2448b3ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af33f8977f034b92b86e9f725bc2b952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf7461ae65574bdca8b899a177f36af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbcab3c4e4dd4ecf9acb27ddac1bf5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccfac25ea76d4b2dac2d40315ed4f653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbfc91f4e35245a8b679c8f82a059b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccc06daa91842f29c8b7b8332370a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb591cf6b284b569fcf7189f9fc1ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e50bde5532174363b6b88687d501cc0d",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcab3c4e4dd4ecf9acb27ddac1bf5d4",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e50bde5532174363b6b88687d501cc0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60f504300604a41b61bc8a5b1a4df0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e860a66d8e204f65ad64eb4c52636a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03917244fb16448ab22feedb46647f49",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7461ae65574bdca8b899a177f36af8",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "eea8bd81a10c4d618a6f843e6f05d596": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_503ba7e9e8a248b19190001803e75471",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af33f8977f034b92b86e9f725bc2b952",
            "value": 435797
          }
        },
        "f700ac13fbff41b5aa81952b78bc44fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5cf129eac140a184fecaa2448b3ddd",
            "placeholder": "​",
            "style": "IPY_MODEL_7d00a33aaa6e46d0851251d77c9e0617",
            "value": " 570/570 [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "f94487c0b3db4e9a857ba09f737db194": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9994549c5d497ca03726edb40a8bd7",
            "placeholder": "​",
            "style": "IPY_MODEL_a0b964c317fc45869de1b9866fe32d46",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.67kB/s]"
          }
        },
        "faf0bacebb594dfaa6be2298a76d7aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb8c175cee654799a19fc9328fe01b92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
