{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 0s 794us/step - loss: 321.1952 - accuracy: 0.1653\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 698us/step - loss: -115.1658 - accuracy: 0.1653\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 677us/step - loss: -240.7643 - accuracy: 0.1653\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 612us/step - loss: -371.4720 - accuracy: 0.1653\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 603us/step - loss: -563.4799 - accuracy: 0.1653\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 625us/step - loss: -802.7951 - accuracy: 0.1653\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 623us/step - loss: -1125.9249 - accuracy: 0.1653\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 617us/step - loss: -1516.2748 - accuracy: 0.1653\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 1ms/step - loss: -2051.6299 - accuracy: 0.1653\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 624us/step - loss: -2782.3599 - accuracy: 0.1653\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 586us/step - loss: -3453.2043 - accuracy: 0.1653\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 587us/step - loss: -4248.8184 - accuracy: 0.1653\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 594us/step - loss: -5416.1523 - accuracy: 0.1653\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 558us/step - loss: -6674.1245 - accuracy: 0.1653\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 550us/step - loss: -8272.4531 - accuracy: 0.1653\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 546us/step - loss: -9924.6689 - accuracy: 0.1653\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 685us/step - loss: -12203.6475 - accuracy: 0.1653\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 613us/step - loss: -14605.0850 - accuracy: 0.1653\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 598us/step - loss: -17853.4004 - accuracy: 0.1653\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 567us/step - loss: -21345.9062 - accuracy: 0.1653\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 583us/step - loss: -25005.9551 - accuracy: 0.1653\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 755us/step - loss: -29493.6641 - accuracy: 0.1653\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 741us/step - loss: -34252.1094 - accuracy: 0.1653\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 1ms/step - loss: -39242.4648 - accuracy: 0.1653\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 635us/step - loss: -45096.2930 - accuracy: 0.1653\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 550us/step - loss: -52074.3242 - accuracy: 0.1653\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 570us/step - loss: -58980.8477 - accuracy: 0.1653\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 525us/step - loss: -66051.1562 - accuracy: 0.1653\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 528us/step - loss: -74397.2734 - accuracy: 0.1653\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 528us/step - loss: -82623.8516 - accuracy: 0.1653\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 559us/step - loss: -92119.4141 - accuracy: 0.1653\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 555us/step - loss: -101472.0000 - accuracy: 0.1653\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 592us/step - loss: -112501.3516 - accuracy: 0.1653\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 625us/step - loss: -124298.1094 - accuracy: 0.1653\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 646us/step - loss: -135765.2344 - accuracy: 0.1653\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 562us/step - loss: -148528.1562 - accuracy: 0.1653\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 557us/step - loss: -161584.2812 - accuracy: 0.1653\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 571us/step - loss: -175850.6094 - accuracy: 0.1653\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 564us/step - loss: -190652.6719 - accuracy: 0.1653\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 578us/step - loss: -206321.0938 - accuracy: 0.1653\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 583us/step - loss: -222676.4531 - accuracy: 0.1653\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 589us/step - loss: -238665.9062 - accuracy: 0.1653\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 578us/step - loss: -255604.7188 - accuracy: 0.1653\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 664us/step - loss: -274299.8750 - accuracy: 0.1653\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 1ms/step - loss: -294104.1875 - accuracy: 0.1653\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 722us/step - loss: -312801.0312 - accuracy: 0.1653\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 559us/step - loss: -333775.9688 - accuracy: 0.1653\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 643us/step - loss: -355962.1875 - accuracy: 0.1653\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 573us/step - loss: -378158.5938 - accuracy: 0.1653\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 570us/step - loss: -399579.2812 - accuracy: 0.1653\n",
      "10/10 [==============================] - 0s 752us/step - loss: -24216.2344 - accuracy: 0.1629\n",
      "Test accuracy: 16.29%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define a function to prepare text data using the tokenizer and specified encoded length\n",
    "def prepare_text_data(texts, tokenizer, encoded_length):\n",
    "    tokenized = tokenizer(texts, padding='max_length', truncation=True, max_length=encoded_length, return_tensors=\"np\")\n",
    "    return tokenized\n",
    "\n",
    "# Import the necessary libraries\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "data = load_dataset(\"climate_fever\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data['test'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the encoding length (e.g., 128, 256, 384, or any value)\n",
    "encoded_length = 384\n",
    "\n",
    "# Prepare data for the neural network\n",
    "train_encoding = prepare_text_data(train_data[\"claim\"], tokenizer, encoded_length)\n",
    "test_encoding = prepare_text_data(test_data[\"claim\"], tokenizer, encoded_length)\n",
    "train_labels = train_data[\"claim_label\"]\n",
    "test_labels = test_data[\"claim_label\"]\n",
    "\n",
    "# Convert data to arrays\n",
    "train_vectors_arrays = train_encoding['input_ids']\n",
    "test_vectors_arrays = test_encoding['input_ids']\n",
    "train_labels_array = np.array(train_labels)\n",
    "test_labels_array = np.array(test_labels)\n",
    "\n",
    "# Create a neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=encoded_length, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the neural network\n",
    "model.fit(train_vectors_arrays, train_labels_array, epochs=50, verbose=1)\n",
    "\n",
    "# Evaluate the neural network on test data\n",
    "loss, accuracy = model.evaluate(test_vectors_arrays, test_labels_array)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "\n",
    "# Access the 'train' split\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Print the first observation\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part 5 - Neural Network for NLP/NeuralNetworkClassificationApp.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#X10sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mtrain[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "dataset.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part 5 - Neural Network for NLP/NeuralNetworkClassificationApp.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Convert labels into integers (0, 1, 2, 3)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=26'>27</a>\u001b[0m label_mapping \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mworld\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSports\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBusiness\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSci/Tech\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m}\n\u001b[0;32m---> <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=27'>28</a>\u001b[0m train_labels_binary \u001b[39m=\u001b[39m [label_mapping[label] \u001b[39mfor\u001b[39;49;00m label \u001b[39min\u001b[39;49;00m train_labels]\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=28'>29</a>\u001b[0m test_labels_binary \u001b[39m=\u001b[39m [label_mapping[label] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m test_labels]\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Convert values into arrays\u001b[39;00m\n",
      "\u001b[1;32m/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part 5 - Neural Network for NLP/NeuralNetworkClassificationApp.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Convert labels into integers (0, 1, 2, 3)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=26'>27</a>\u001b[0m label_mapping \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mworld\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSports\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBusiness\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSci/Tech\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m}\n\u001b[0;32m---> <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=27'>28</a>\u001b[0m train_labels_binary \u001b[39m=\u001b[39m [label_mapping[label] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m train_labels]\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=28'>29</a>\u001b[0m test_labels_binary \u001b[39m=\u001b[39m [label_mapping[label] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m test_labels]\n\u001b[1;32m     <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#W4sdnNjb2RlLXZmcw%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Convert values into arrays\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load your dataset\n",
    "data= load_dataset(\"ag_news\")\n",
    "\n",
    "train_texts = data[\"train\"][\"text\"]\n",
    "train_labels = data[\"train\"][\"label\"]\n",
    "test_texts = data[\"test\"][\"text\"]\n",
    "test_labels = data[\"test\"][\"label\"]\n",
    "\n",
    "# Consider top 5000 frequent words\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "train_vectors = vectorizer.transform(train_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)\n",
    "\n",
    "# Convert the sklearn vectors to numpy arrays\n",
    "train_vectors_arrays = train_vectors.toarray()\n",
    "test_vectors_arrays = test_vectors.toarray()\n",
    "\n",
    "# Convert labels into integers (0, 1, 2, 3)\n",
    "label_mapping = {\"world\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3}\n",
    "train_labels_binary = [label_mapping[label] for label in train_labels]\n",
    "test_labels_binary = [label_mapping[label] for label in test_labels]\n",
    "\n",
    "# Convert values into arrays\n",
    "train_labels_array = np.array(train_labels_binary)\n",
    "test_labels_array = np.array(test_labels_binary)\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=5000, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # Output layer with 4 classes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to one-hot encoded vectors for multi-class classification\n",
    "from keras.utils import to_categorical\n",
    "train_labels_onehot = to_categorical(train_labels_array, num_classes=4)\n",
    "test_labels_onehot = to_categorical(test_labels_array, num_classes=4)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_vectors_arrays, train_labels_onehot, epochs=10, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_vectors_arrays, test_labels_onehot)\n",
    "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part 5 - Neural Network for NLP/NeuralNetworkClassificationApp.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#X11sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mText:\u001b[39m\u001b[39m\"\u001b[39m, train_texts[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://github/gonzalovaldenebro/NaturalLanguageProcessing-Portfolio/Part%205%20-%20Neural%20Network%20for%20NLP/NeuralNetworkClassificationApp.ipynb#X11sdnNjb2RlLXZmcw%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLabel:\u001b[39m\u001b[39m\"\u001b[39m, train_labels[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_texts' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", train_texts[0])\n",
    "print(\"Label:\", train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(test_labels)\n",
    "print(\"Unique labels in the dataset:\", unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(train_labels)\n",
    "print(\"Unique labels in the dataset:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 3s 649us/step - loss: 0.3800 - accuracy: 0.8719\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 3s 672us/step - loss: 0.2338 - accuracy: 0.9200\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 2s 666us/step - loss: 0.2126 - accuracy: 0.9265\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 2s 638us/step - loss: 0.1975 - accuracy: 0.9308\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 2s 632us/step - loss: 0.1845 - accuracy: 0.9350\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 2s 636us/step - loss: 0.1723 - accuracy: 0.9387\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 2s 635us/step - loss: 0.1603 - accuracy: 0.9440\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 2s 633us/step - loss: 0.1491 - accuracy: 0.9471\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 2s 636us/step - loss: 0.1384 - accuracy: 0.9508\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 2s 638us/step - loss: 0.1284 - accuracy: 0.9548\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 2s 636us/step - loss: 0.1193 - accuracy: 0.9585\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 2s 641us/step - loss: 0.1106 - accuracy: 0.9614\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 2s 647us/step - loss: 0.1025 - accuracy: 0.9642\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 2s 647us/step - loss: 0.0952 - accuracy: 0.9666\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 2s 645us/step - loss: 0.0877 - accuracy: 0.9696\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 2s 657us/step - loss: 0.0817 - accuracy: 0.9717\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 2s 654us/step - loss: 0.0753 - accuracy: 0.9742\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 3s 683us/step - loss: 0.0697 - accuracy: 0.9763\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 3s 672us/step - loss: 0.0645 - accuracy: 0.9782\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 3s 673us/step - loss: 0.0600 - accuracy: 0.9794\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 3s 673us/step - loss: 0.0554 - accuracy: 0.9811\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 3s 675us/step - loss: 0.0512 - accuracy: 0.9829\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 3s 675us/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 3s 679us/step - loss: 0.0444 - accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 3s 673us/step - loss: 0.0409 - accuracy: 0.9868\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 3s 675us/step - loss: 0.0383 - accuracy: 0.9876\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 2s 664us/step - loss: 0.0354 - accuracy: 0.9887\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 3s 696us/step - loss: 0.0332 - accuracy: 0.9894\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 3s 704us/step - loss: 0.0310 - accuracy: 0.9902\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 3s 714us/step - loss: 0.0290 - accuracy: 0.9909\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 3s 715us/step - loss: 0.0272 - accuracy: 0.9913\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 3s 696us/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 3s 692us/step - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 3s 693us/step - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 3s 696us/step - loss: 0.0214 - accuracy: 0.9935\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 3s 698us/step - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 3s 715us/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 3s 702us/step - loss: 0.0184 - accuracy: 0.9943\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 3s 694us/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 3s 693us/step - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 3s 705us/step - loss: 0.0159 - accuracy: 0.9951\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 3s 721us/step - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 3s 710us/step - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 3s 698us/step - loss: 0.0147 - accuracy: 0.9956\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 3s 751us/step - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 46/100\n",
      "2851/3750 [=====================>........] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load your dataset\n",
    "data = load_dataset(\"ag_news\")\n",
    "\n",
    "train_texts = data[\"train\"][\"text\"]\n",
    "train_labels = data[\"train\"][\"label\"]\n",
    "test_texts = data[\"test\"][\"text\"]\n",
    "test_labels = data[\"test\"][\"label\"]\n",
    "\n",
    "# Consider top 5000 frequent words\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "train_vectors = vectorizer.transform(train_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)\n",
    "\n",
    "# Convert the sklearn vectors to numpy arrays\n",
    "train_vectors_arrays = train_vectors.toarray()\n",
    "test_vectors_arrays = test_vectors.toarray()\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=5000, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # Output layer with 4 classes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to one-hot encoded vectors for multi-class classification\n",
    "train_labels_onehot = to_categorical(train_labels, num_classes=4)\n",
    "test_labels_onehot = to_categorical(test_labels, num_classes=4)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_vectors_arrays, train_labels_onehot, epochs=100, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_vectors_arrays, test_labels_onehot)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
